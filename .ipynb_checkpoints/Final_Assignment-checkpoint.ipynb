{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helio Inaba - CQF June 2023 Final Project \n",
    "## Optimal Hedging with Advanced Delta Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "#pd.set_option('display.max_columns', None)\n",
    "pd.reset_option('^display.', silent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{center}\n",
    "\\begin{tabular}{ c c c }\n",
    " cell1 & cell2 & cell3 \\\\ \n",
    " cell4 & cell5 & cell6 \\\\  \n",
    " cell7 & cell8 & cell9    \n",
    "\\end{tabular}\n",
    "\\end{center}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(data, bins):\n",
    "    \n",
    "    return 1/(data.std()*np.sqrt(2*np.pi))*(np.exp(-(bins - data.mean())**2/(2*data.std()**2)))\n",
    "\n",
    "\n",
    "def black_scholes(S, K, sigma, T, r):\n",
    "\n",
    "    d1 = ((np.log(S/K)+(r+(sigma**2)/2)*T)/(sigma*np.sqrt(T)))\n",
    "    d2 = d1-sigma*np.sqrt(T)\n",
    "    n_d1 = norm.cdf(d1)\n",
    "    n_d2 = norm.cdf(d2)\n",
    "\n",
    "    V = n_d1*S-n_d2*K*np.exp(-r*T)\n",
    "    \n",
    "    return V\n",
    "\n",
    "\n",
    "def bs_delta(S, K, sigma, T, r):\n",
    "\n",
    "    d1 = ((np.log(S/K)+(r+(sigma**2)/2)*T)/(sigma*np.sqrt(T)))\n",
    "    n_d1 = norm.cdf(d1)\n",
    "    \n",
    "    return n_d1\n",
    "\n",
    "\n",
    "def bs_gamma(S, K, sigma, T, r):\n",
    "\n",
    "    d1 = ((np.log(S/K)+(r+(sigma**2)/2)*T)/(sigma*np.sqrt(T)))\n",
    "    \n",
    "    return norm.pdf(d1)/(S*sigma*np.sqrt(T))\n",
    "\n",
    "\n",
    "def bs_vega(S, K, sigma, T, r):\n",
    "\n",
    "    d1 = ((np.log(S/K)+(r+(sigma**2)/2)*T)/(sigma*np.sqrt(T)))\n",
    "    \n",
    "    return S*norm.pdf(d1)*np.sqrt(T)\n",
    "\n",
    "\n",
    "def bs_theta(S, K, sigma, T, r):\n",
    "\n",
    "    d1 = ((np.log(S/K)+(r+(sigma**2)/2)*T)/(sigma*np.sqrt(T)))\n",
    "    d2 = d1-sigma*np.sqrt(T)\n",
    "    n_d2 = norm.cdf(d2)\n",
    "\n",
    "    theta = -S*norm.pdf(d1)*sigma/(2*np.sqrt(T))\n",
    "    theta -= r*K*np.exp(-r*T)*n_d2\n",
    "\n",
    "    return theta\n",
    "\n",
    "def bs_rho(S, K, sigma, T, r):\n",
    "\n",
    "    d1 = ((np.log(S/K)+(r+(sigma**2)/2)*T)/(sigma*np.sqrt(T)))\n",
    "    d2 = d1-sigma*np.sqrt(T)\n",
    "    n_d2 = norm.cdf(d2)\n",
    "\n",
    "    return K*T*np.exp(-r*T)*n_d2\n",
    "\n",
    "\n",
    "def euler_maruyama(s0, expiry_T, sigma, return_rate, n_periods, n_simulations):\n",
    "\n",
    "    prices = np.zeros((n_periods, n_simulations))\n",
    "    prices[0] = s0\n",
    "\n",
    "    for i in range(1, n_periods):\n",
    "\n",
    "        prices[i] = prices[i-1]*(1 + return_rate*expiry_T/n_periods + sigma*np.sqrt(expiry_T/n_periods)*np.random.normal(loc=0.0, scale=1.0, size=n_simulations))\n",
    "\n",
    "    prices = pd.DataFrame(prices)\n",
    "    prices.index.name = 'period'\n",
    "    prices.index.columns = 'simulation'\n",
    "\n",
    "    return prices\n",
    "\n",
    "\n",
    "def milstein(s0, expiry_T, sigma, return_rate, n_periods, n_simulations):\n",
    "\n",
    "    prices = np.zeros((n_simulations, n_periods+1))\n",
    "    prices[:,0] = s0\n",
    "\n",
    "    A_matrix = np.sqrt(expiry_T/n_periods)*np.tri(n_periods,n_periods)\n",
    "    z = np.random.normal(loc=0.0, scale=1.0, size=(n_periods,n_simulations))\n",
    "\n",
    "    wiener_matrix = np.matmul(A_matrix, z)\n",
    "    wiener_matrix = np.transpose(wiener_matrix)\n",
    "\n",
    "    prices[:,1:] = s0*np.exp((return_rate-(sigma**2)/2)*np.linspace(start=expiry_T/n_periods,stop=expiry_T,num=n_periods)+sigma*wiener_matrix)\n",
    "\n",
    "    prices = pd.DataFrame(np.transpose(prices))\n",
    "    prices.index.name = 'period'\n",
    "    prices.index.columns = 'simulation'\n",
    "\n",
    "    return prices\n",
    "\n",
    "def antithetic_variables(s0, expiry_T, sigma, return_rate, n_periods, n_simulations):\n",
    "\n",
    "    prices_plus = np.zeros((n_simulations, n_periods+1))\n",
    "    prices_plus[:,0] = s0\n",
    "\n",
    "    prices_minus = np.zeros((n_simulations, n_periods+1))\n",
    "    prices_minus[:,0] = s0\n",
    "\n",
    "    A_matrix = np.sqrt(expiry_T/n_periods)*np.tri(n_periods,n_periods)\n",
    "    z = np.random.normal(loc=0.0, scale=1.0, size=(n_periods,n_simulations))\n",
    "    z_minus = -z\n",
    "\n",
    "    wiener_matrix = np.matmul(A_matrix, z)\n",
    "    wiener_matrix = np.transpose(wiener_matrix)\n",
    "\n",
    "    wiener_matrix_minus = np.matmul(A_matrix, z_minus)\n",
    "    wiener_matrix_minus = np.transpose(wiener_matrix_minus)\n",
    "\n",
    "    prices_plus[:,1:] = s0*np.exp((return_rate-(sigma**2)/2)*np.linspace(start=expiry_T/n_periods,stop=expiry_T,num=n_periods)+sigma*wiener_matrix)\n",
    "    prices_minus[:,1:] = s0*np.exp((return_rate-(sigma**2)/2)*np.linspace(start=expiry_T/n_periods,stop=expiry_T,num=n_periods)+sigma*wiener_matrix_minus)\n",
    "\n",
    "    prices_plus = pd.DataFrame(np.transpose(prices_plus))\n",
    "    prices_minus = pd.DataFrame(np.transpose(prices_minus))\n",
    "    \n",
    "    prices_plus.index.name = 'period'\n",
    "    prices_plus.index.columns = 'simulation'\n",
    "\n",
    "    prices_minus.index.name = 'period'\n",
    "    prices_minus.index.columns = 'simulation'\n",
    "\n",
    "    return prices_plus, prices_minus\n",
    "\n",
    "\n",
    "def fill_bridge_array(a, b, delta_t, z=None):\n",
    "    \n",
    "    if type(z) == type(None):\n",
    "        return (a+b)/2 + np.sqrt((delta_t/4))*np.random.normal(loc=0.0, scale=1.0, size=1)[0]\n",
    "    else:\n",
    "        return (a+b)/2 + np.sqrt((delta_t/4))*z\n",
    "\n",
    "def sobol_prices(s0, expiry_T, sigma, return_rate, n_periods, n_simulations):\n",
    "\n",
    "    n = int(np.log2(n_periods))\n",
    "\n",
    "    compounding_array = np.exp((return_rate-(sigma**2)/2)*np.linspace(start=expiry_T/n_periods,stop=expiry_T,num=n_periods))\n",
    "\n",
    "    W_t = np.empty((n_periods+1, n_simulations))\n",
    "    W_t[:] = np.nan\n",
    "    W_t[0] = 0.0\n",
    "\n",
    "    prices = np.zeros((n_periods+1, n_simulations))\n",
    "    prices = pd.DataFrame(prices, index=np.arange(0, 1+1/(2**n), 1/(2**n)))\n",
    "    prices.iloc[0] = s0\n",
    "\n",
    "    sampler = scipy.stats.qmc.Sobol(d=n_periods, scramble=True)\n",
    "    sample = sampler.random_base2(int(np.log2(n_simulations)))\n",
    "    sample = np.transpose(sample)\n",
    "    norm_sample = norm.ppf(sample)\n",
    "\n",
    "    k = 0\n",
    "    W_t[-1,:] = norm_sample[k,:]\n",
    "\n",
    "    df_wt = pd.DataFrame(W_t, index=np.arange(0, 1+1/(2**n), 1/(2**n)))\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        \n",
    "        for j in ((1/2)**i)*np.arange(1, 2**(i)+1, 2):\n",
    "            k+=1\n",
    "            df_wt.loc[j] = fill_bridge_array(a=df_wt.loc[j-(1/2)**i], b=df_wt.loc[j+(1/2)**i], delta_t=(1/2)**(i-1), z=norm_sample[k,:])\n",
    "            \n",
    "    prices.iloc[1:] = s0*(np.exp(sigma*df_wt.iloc[1:,].values).T*compounding_array).T\n",
    "    prices.index = prices.index*expiry_T\n",
    "\n",
    "    prices.index.name = 'period'\n",
    "    prices.index.columns = 'simulation'\n",
    "\n",
    "    return prices\n",
    "\n",
    "\n",
    "def fill_bridge(a, b, delta_t, z=None):\n",
    "\n",
    "    \n",
    "    if z == None:\n",
    "        return (a+b)/2 + np.sqrt((delta_t/4))*np.random.normal(loc=0.0, scale=1.0, size=1)[0]\n",
    "    else:\n",
    "        return (a+b)/2 + np.sqrt((delta_t/4))*z\n",
    "    \n",
    "\n",
    "def brownian_bridge(w0, w1, n):\n",
    "\n",
    "    df_wt = pd.DataFrame(columns=['W_t'], index=np.arange(0, 1+1/(2**n), 1/(2**n)))\n",
    "\n",
    "    df_wt.iloc[0] = w0\n",
    "    df_wt.iloc[-1] = w1\n",
    "\n",
    "    for i in range(1, n+1):\n",
    "        \n",
    "        for j in ((1/2)**i)*np.arange(1, 2**(i)+1, 2):\n",
    "\n",
    "            df_wt.loc[j] = fill_bridge(a=df_wt.loc[j-(1/2)**i], b=df_wt.loc[j+(1/2)**i], delta_t=(1/2)**(i-1))\n",
    "\n",
    "    return df_wt\n",
    "\n",
    "\n",
    "def call_price(s0, strike_E, expiry_T, sigma, risk_free, n_periods, n_simulations):\n",
    "\n",
    "    prices_path = euler_maruyama(s0, expiry_T, sigma, risk_free, n_periods, n_simulations)\n",
    "    payoff = np.maximum(prices_path.iloc[-1]-strike_E,0)\n",
    "    \n",
    "    return [np.exp(-risk_free*(expiry_T))*np.mean(payoff),\n",
    "            pd.Series(payoff*np.exp(-risk_free*(expiry_T)))]\n",
    "\n",
    "\n",
    "def call_price_milstein(s0, strike_E, expiry_T, sigma, risk_free, n_periods, n_simulations):\n",
    "\n",
    "    prices_path =  milstein(s0, expiry_T, sigma, risk_free, n_periods, n_simulations)\n",
    "    payoff = np.maximum(prices_path.iloc[-1]-strike_E,0)\n",
    "    \n",
    "    return [np.exp(-risk_free*(expiry_T))*np.mean(payoff),\n",
    "            pd.Series(payoff*np.exp(-risk_free*(expiry_T)))]\n",
    "\n",
    "\n",
    "def call_price_anti(s0, strike_E, expiry_T, sigma, risk_free, n_periods, n_simulations):\n",
    "\n",
    "    prices_plus, prices_minus = antithetic_variables(s0, expiry_T, sigma, risk_free, n_periods, n_simulations)\n",
    "    payoff = .5*(np.maximum(prices_plus.iloc[-1]-strike_E,0)+np.maximum(prices_minus.iloc[-1]-strike_E,0))\n",
    "    \n",
    "    return [np.exp(-risk_free*(expiry_T))*np.mean(payoff),\n",
    "            pd.Series(payoff*np.exp(-risk_free*(expiry_T)))]\n",
    "\n",
    "\n",
    "def call_price_sobol(s0, strike_E, expiry_T, sigma, risk_free, n_periods, n_simulations):\n",
    "\n",
    "    prices_path = sobol_prices(s0, expiry_T, sigma, risk_free, n_periods, n_simulations)\n",
    "    payoff = np.maximum(prices_path.iloc[-1]-strike_E,0)\n",
    "\n",
    "    return [np.exp(-risk_free*(expiry_T))*np.mean(payoff),\n",
    "            payoff*np.exp(-risk_free*(expiry_T))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Volatility Arb with improved GBM and Monte-Carlo ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Consider improvements to GBM asset evolution (Euler-Maruyana/Milstein schemes). <br> Optionally, can consider modelling asset with jumps, eg, Merton jump diffusion, without going into stochastic volatility, eg Heston-Nandi. <br> Variance Gamma is also relevant but suited for single-name assets with extreme movements.\n",
    " - consider MC variance reduction techniques, such as antithetic variates; <br>\n",
    " - best practice is low discrepancy sequences, eg Sobol with the Brownian bridge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mc_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(antithetic_option_prices.expanding().var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sobol_option_prices.expanding().var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 50\n",
    "K = 55\n",
    "sigma = .30\n",
    "r = .1\n",
    "T = 360/360\n",
    "\n",
    "bs_price = black_scholes(S, K, sigma, T, r)\n",
    "\n",
    "df_mc_errors = pd.DataFrame(columns=['Euler_Maruyama', 'Milstein', 'Antithetic', 'Sobol_Brownian_Bridge'])\n",
    "df_mc_variances = pd.DataFrame(columns=['Euler_Maruyama', 'Milstein', 'Antithetic', 'Sobol_Brownian_Bridge'])\n",
    "\n",
    "n_simulations = 2**18\n",
    "n_periods = 2**9\n",
    "\n",
    "euler_maruyama_option_prices = pd.Series(call_price(s0=S, strike_E=K, expiry_T=T, sigma=sigma, risk_free=r, n_periods=n_periods, n_simulations=int(n_simulations))[1])\n",
    "milstein_option_prices = pd.Series(call_price_milstein(s0=S, strike_E=K, expiry_T=T, sigma=sigma, risk_free=r, n_periods=n_periods, n_simulations=int(n_simulations))[1])\n",
    "antithetic_option_prices = pd.Series(call_price_anti(s0=S, strike_E=K, expiry_T=T, sigma=sigma, risk_free=r, n_periods=n_periods, n_simulations=int(n_simulations))[1])\n",
    "sobol_option_prices = call_price_sobol(s0=S, strike_E=K, expiry_T=T, sigma=sigma, risk_free=r, n_periods=n_periods, n_simulations=int(n_simulations))[1]\n",
    "\n",
    "df_mc_errors['Euler_Maruyama'] = bs_price - euler_maruyama_option_prices.expanding().mean()\n",
    "df_mc_errors['Milstein'] = bs_price - milstein_option_prices.expanding().mean()\n",
    "df_mc_errors['Antithetic'] = bs_price - antithetic_option_prices.expanding().mean()\n",
    "df_mc_errors['Sobol_Brownian_Bridge'] = bs_price - sobol_option_prices.expanding().mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "sns.lineplot(df_mc_errors.loc[1024:], \n",
    "             ax=ax)\n",
    "\n",
    "plt.axhline(y=0.0, color='black', linestyle='--')\n",
    "\n",
    "ax.set_xscale('log', base=2)\n",
    "plt.show()\n",
    "\n",
    "print(df_mc_errors.iloc[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of Sobol sequences with Brownian Bridge greatly improves the convergence of Monte Carlo calculation by orders of magnitude.\n",
    "\n",
    "The use of antithetic variables decreses the variance of results without the necessity of further generation of random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# sns.lineplot(df_mc_variances.loc[1024:], \n",
    "#              ax=ax)\n",
    "\n",
    "# ax.set_xscale('log', base=2)\n",
    "# plt.show()\n",
    "\n",
    "# print(df_mc_variances.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mc_variances = pd.DataFrame(columns=['Euler_Maruyama', 'Milstein', 'Antithetic', 'Sobol_Brownian_Bridge'])\n",
    "\n",
    "df_mc_variances['Euler_Maruyama'] = euler_maruyama_option_prices.expanding().var()\n",
    "df_mc_variances['Milstein'] = milstein_option_prices.expanding().var()\n",
    "df_mc_variances['Antithetic'] = antithetic_option_prices.expanding().var()\n",
    "df_mc_variances['Sobol_Brownian_Bridge'] = sobol_option_prices.expanding().var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((bs_price - milstein_option_prices)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((bs_price - sobol_option_prices)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Under the condition of known future realised volatility $ V_{a} > V_{i} $ , analytically and with Monte-Carlo confirm the items below. <br> Report with both, complete mathematical workings to fold $ P\\&L_{t} $ and simulations of $ P\\&L_{t} $.\n",
    " - confirm actual volatility hedging leads to the known total $ P\\&L $;\n",
    " - confirm and demonstrate implied volatility hedging leads to uncertain total, path-dependent $ P\\&L $, and characterise on which parameters/Greeks it depends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Think of additional analysis: consider how $ P\\&L $ decomposes in terms of Greeks. <br> What is\n",
    "the impact of time-dependent Gamma $ \\Gamma_{t} $? What about $ r^2\n",
    "− \\sigma_{imp}\\delta t $? <br> Consider findings\n",
    "from Part II MVD modelling, what are the implications of hedging with the smaller delta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2**19\n",
    "r = 0.1\n",
    "sigma = .3\n",
    "\n",
    "data = milstein(s0=S, expiry_T=1, sigma=sigma, return_rate=r, n_periods=1, n_simulations=n).iloc[-1]\n",
    "\n",
    "fx = [np.exp(-(x**2)/2)/np.sqrt(2*np.pi) for x in np.linspace(-3,3,n)]\n",
    "\n",
    "x_lognorm = S*np.exp(r-(sigma*sigma)/2)*np.exp(np.linspace(-3,3,n)*sigma)\n",
    "y_lognorm = fx\n",
    "y_lognorm = y_lognorm/sum(np.diff(x_lognorm)*y_lognorm[1:])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.histplot(data,\n",
    "             stat='density',\n",
    "             bins=1000,\n",
    "             ax=ax)\n",
    "\n",
    "sns.lineplot(ax=ax,\n",
    "             x=x_lognorm,\n",
    "             y=y_lognorm,\n",
    "             color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Under the condition of known future realised volatility $ V_{a} > V_{i} $ , analytically and with Monte-Carlo confirm the items below. <br> Report with both, complete mathematical workings to fold $ P\\&L_{t} $ and simulations of $ P\\&L_{t} $.\n",
    " - confirm actual volatility hedging leads to the known total $ P\\&L $;\n",
    " - confirm and demonstrate implied volatility hedging leads to uncertain total, path-dependent $ P\\&L $, and characterise on which parameters/Greeks it depends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_hedged_ptf(stock_path, K, T, sigma, r):\n",
    "\n",
    "    df_hedged_ptf = pd.DataFrame(columns=['Cash_Position', 'Cash_Rebalance', 'Daily_Interest', '#_Stocks', 'Ptf_Stock', 'Ptf_Total'],\n",
    "                                 index=range(0,len(stock_path)))\n",
    "    \n",
    "    \n",
    "    s0 = stock_path[0]\n",
    "    n_periods = len(stock_path)\n",
    "    \n",
    "    df_hedged_ptf['Cash_Position'] = [0.0]*len(df_hedged_ptf)\n",
    "    df_hedged_ptf['Cash_Rebalance'] = [0.0]*len(df_hedged_ptf)\n",
    "    df_hedged_ptf['Daily_Interest'] = [0.0]*len(df_hedged_ptf)\n",
    "\n",
    "    df_hedged_ptf['#_Stocks'] = [bs_delta(S=s, K=K, sigma=sigma, T=T*(1-t/n_periods), r=r) for t,s in zip(df_hedged_ptf.index, stock_path)]\n",
    "    df_hedged_ptf.loc[0, 'Cash_Position'] = -df_hedged_ptf.loc[0, '#_Stocks']*s0\n",
    "\n",
    "    df_hedged_ptf['Ptf_Stock'] = df_hedged_ptf['#_Stocks']*stock_path\n",
    "    df_hedged_ptf['Cash_Rebalance'] = -df_hedged_ptf['#_Stocks'].diff().fillna(0)*stock_path\n",
    "\n",
    "    for i in df_hedged_ptf.index[1:]:\n",
    "\n",
    "        df_hedged_ptf.loc[i, 'Daily_Interest'] = df_hedged_ptf.loc[i-1, 'Cash_Position']*r*T/n_periods\n",
    "        df_hedged_ptf.loc[i, 'Cash_Position'] = df_hedged_ptf.loc[i-1, 'Cash_Position'] + df_hedged_ptf.loc[i, 'Cash_Rebalance'] + df_hedged_ptf.loc[i, 'Daily_Interest']\n",
    "\n",
    "    df_hedged_ptf['Ptf_Total'] = df_hedged_ptf['Cash_Position'] + df_hedged_ptf['Ptf_Stock']\n",
    "\n",
    "    return df_hedged_ptf\n",
    "\n",
    "\n",
    "def call_ptf(stock_path, K, T,sigma, r):\n",
    "\n",
    "    s0 = stock_path[0]\n",
    "    n_periods = len(stock_path)\n",
    "\n",
    "    V_i = black_scholes(S=s0, K=K, sigma=sigma, T=T, r=r)\n",
    "\n",
    "    df_call_ptf = pd.DataFrame(columns=['Call_Price', 'Call_Carry', 'Call_PnL'],\n",
    "                               index=range(0,len(stock_path)))\n",
    "\n",
    "    df_call_ptf['Call_Price'] = [black_scholes(S=s, K=K, sigma=sigma, T=T*(1-t/n_periods), r=r) for t,s in zip(df_call_ptf.index, stock_path)]\n",
    "    df_call_ptf['Call_Carry'] = [V_i*(1-np.exp(r*T*t/n_periods)) for t in df_call_ptf.index]\n",
    "    df_call_ptf['Call_PnL'] = df_call_ptf['Call_Price'] - df_call_ptf.loc[0,'Call_Price'] + df_call_ptf['Call_Carry']\n",
    "    \n",
    "    df_call_ptf['Call_Delta'] = [bs_delta(S=s, K=K, sigma=sigma, T=T*(1-t/n_periods), r=r) for t,s in zip(df_call_ptf.index, stock_path)]\n",
    "    df_call_ptf['Call_Gamma'] = [bs_gamma(S=s, K=K, sigma=sigma, T=T*(1-t/n_periods), r=r) for t,s in zip(df_call_ptf.index, stock_path)]\n",
    "    df_call_ptf['Call_Theta'] = [bs_theta(S=s, K=K, sigma=sigma, T=T*(1-t/n_periods), r=r) for t,s in zip(df_call_ptf.index, stock_path)]\n",
    "    \n",
    "    df_call_ptf['Call_Rho'] = [bs_rho(S=s, K=K, sigma=sigma, T=T*(1-t/n_periods), r=r) for t,s in zip(df_call_ptf.index, stock_path)]\n",
    "    df_call_ptf['Call_Vega'] = [bs_vega(S=s, K=K, sigma=sigma, T=T*(1-t/n_periods), r=r) for t,s in zip(df_call_ptf.index, stock_path)]\n",
    "\n",
    "    df_call_ptf['PnL_Delta'] = (df_call_ptf['Call_Delta'].shift(1)*stock_path.diff()).cumsum()\n",
    "    df_call_ptf['PnL_Gamma'] = (df_call_ptf['Call_Gamma'].shift(1)*np.square(stock_path.diff())).cumsum()/2\n",
    "    df_call_ptf['PnL_Theta'] = (df_call_ptf['Call_Theta'].shift(1)*T/n_periods).cumsum()\n",
    "    df_call_ptf['PnL_Carry'] = df_call_ptf['Call_Carry']\n",
    "\n",
    "    df_call_ptf['PnL_Greeks'] = df_call_ptf[['PnL_Delta','PnL_Gamma','PnL_Theta','PnL_Carry']].sum(axis=1)\n",
    "\n",
    "    return df_call_ptf\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 50\n",
    "K = 55\n",
    "sigma_i = .30\n",
    "sigma_a = .40\n",
    "\n",
    "r = .1\n",
    "T = 1.0 #in years\n",
    "\n",
    "V_i = black_scholes(S, K, sigma_i, T, r)\n",
    "V_a = black_scholes(S, K, sigma_a, T, r)\n",
    "\n",
    "n_periods = 10000\n",
    "\n",
    "df_price_paths = euler_maruyama(s0=S, expiry_T=T, sigma=sigma_a, return_rate=r, n_periods=n_periods, n_simulations=10)\n",
    "\n",
    "for i in df_price_paths.columns:\n",
    "\n",
    "    stock_path = df_price_paths.loc[:, i]\n",
    "\n",
    "    df_call = call_ptf(stock_path = stock_path, K=K, T=T,sigma=sigma_i, r=r).Call_PnL\n",
    "    df_ptf = delta_hedged_ptf(stock_path = stock_path, K=K,T=T, sigma=sigma_a, r=r).Ptf_Total\n",
    "\n",
    "    plt.plot(df_call - df_ptf)\n",
    "\n",
    "plt.axhline(y=np.exp(r*T)*(V_a-V_i), color='black', linestyle='--')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hedging with actual volatiliy leads to a predicted PnL of V_a - V_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1.0\n",
    "\n",
    "V_i = black_scholes(S, K, sigma_i, T, r)\n",
    "V_a = black_scholes(S, K, sigma_a, T, r)\n",
    "\n",
    "n_periods = 10000\n",
    "\n",
    "#df_price_paths = euler_maruyama(s0=S, expiry_T=T, sigma=sigma_a, return_rate=r, n_periods=n_periods, n_simulations=10)\n",
    "\n",
    "for i in df_price_paths.columns[0:1]:\n",
    "\n",
    "    stock_path = df_price_paths.loc[:, i]\n",
    "\n",
    "    df_call = call_ptf(stock_path = stock_path, K=K, T=T,sigma=sigma_i, r=r).Call_PnL\n",
    "    df_ptf = delta_hedged_ptf(stock_path = stock_path, K=K,T=T, sigma=sigma_i, r=r).Ptf_Total\n",
    "\n",
    "    plt.plot(df_call - df_ptf)\n",
    "\n",
    "plt.axhline(y=np.exp(r*T)*(V_a-V_i), color='black', linestyle='--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_periods = 2**15\n",
    "# T = 1\n",
    "\n",
    "# path_foo = euler_maruyama(s0=S, expiry_T=T, sigma=sigma_a, return_rate=r, n_periods=n_periods, n_simulations=1).iloc[:,0]\n",
    "# path_foo = path_foo.to_frame(name='Stock_Price')\n",
    "\n",
    "# #path_foo = path_foo.to_frame(name='Stock_Price')\n",
    "\n",
    "# path_foo['Call_Price'] = [black_scholes(S=s, K=K, sigma=sigma_i, T=T*(1-t/n_periods), r=r) for t,s in zip(path_foo.index, path_foo.Stock_Price)]\n",
    "# path_foo['Call_Delta_i'] = [bs_delta(S=s, K=K, sigma=sigma_i, T=T*(1-t/n_periods), r=r) for t,s in zip(path_foo.index, path_foo.Stock_Price)]\n",
    "# path_foo['Call_Delta_a'] = [bs_delta(S=s, K=K, sigma=sigma_a, T=T*(1-t/n_periods), r=r) for t,s in zip(path_foo.index, path_foo.Stock_Price)]\n",
    "\n",
    "# path_foo['Call_Carry'] = [-V_i*r*t*T/n_periods for t in path_foo.index]\n",
    "# path_foo['Call_PnL'] = path_foo['Call_Price'] - path_foo.loc[0,'Call_Price'] + path_foo['Call_Carry']\n",
    "\n",
    "# path_foo['Cash_Position'] = [0.0]*len(path_foo)\n",
    "# path_foo['Cash_Rebalance'] = [0.0]*len(path_foo)\n",
    "# path_foo['Daily_Interest'] = [0.0]*len(path_foo)\n",
    "\n",
    "# path_foo['#_Stocks'] = [bs_delta(S=s, K=K, sigma=sigma_a, T=T*(1-t/n_periods), r=r) for t,s in zip(path_foo.index, path_foo.Stock_Price)]\n",
    "# path_foo.loc[0, 'Cash_Position'] = -path_foo.loc[0, 'Call_Delta_a']*path_foo.loc[0, 'Stock_Price']\n",
    "\n",
    "# path_foo['Ptf_Stock'] = path_foo['#_Stocks']*path_foo['Stock_Price']\n",
    "# path_foo['Cash_Rebalance'] = -path_foo['#_Stocks'].diff().fillna(0)*path_foo['Stock_Price']\n",
    "\n",
    "# for i in path_foo.index[1:]:\n",
    "\n",
    "#     path_foo.loc[i, 'Daily_Interest'] = path_foo.loc[i-1, 'Cash_Position']*r*T/n_periods\n",
    "#     path_foo.loc[i, 'Cash_Position'] = path_foo.loc[i-1, 'Cash_Position'] + path_foo.loc[i, 'Cash_Rebalance'] + path_foo.loc[i, 'Daily_Interest']\n",
    "\n",
    "# path_foo['Ptf_Total'] = path_foo['Cash_Position'] + path_foo['Ptf_Stock']\n",
    "\n",
    "# plt.plot(path_foo['Call_PnL'] - path_foo['Ptf_Total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Think of additional analysis: consider how $ P\\&L $ decomposes in terms of Greeks. <br> What is\\\n",
    "the impact of time-dependent Gamma $ \\Gamma_{t} $? <br> What about $ r^2\n",
    "− \\sigma_{imp}\\delta t $? <br> Consider findings\n",
    "from Part II MVD modelling, what are the implications of hedging with the smaller delta?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $Total P\\&L \\approx \\sum_{t}^{T} \\frac{1}{2} \\Gamma_{t} S^{2}_{t}\\left [ r^2_{t} -\\sigma_{t,imp}^2 \\Delta t\\right ] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ptf.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_path = df_price_paths.loc[:, i]\n",
    "\n",
    "df_call = call_ptf(stock_path = stock_path, K=K, T=T,sigma=sigma_i, r=r)\n",
    "df_ptf = -delta_hedged_ptf(stock_path = stock_path, K=K,T=T, sigma=sigma_i, r=r)\n",
    "\n",
    "\n",
    "df_total = df_call.merge(df_ptf, right_index=True, left_index=True)\n",
    "\n",
    "df_total['PnL_Total'] = df_total[['Call_PnL', 'Ptf_Total']].sum(axis=1)\n",
    "df_total['PnL_Delta_Total'] = df_total.PnL_Delta + df_total.Ptf_Stock.diff(1).cumsum() + df_total.Cash_Rebalance.cumsum()\n",
    "df_total['Total_Carry'] = df_total['PnL_Carry'] + df_total['Daily_Interest'].cumsum()\n",
    "\n",
    "\n",
    "df_total[['PnL_Total','PnL_Gamma','PnL_Delta_Total','PnL_Theta','Total_Carry']].plot()\n",
    "\n",
    "for col in ['PnL_Total','PnL_Gamma','PnL_Delta_Total','PnL_Theta','Total_Carry']:\n",
    "    \n",
    "    plt.annotate('%.2f' % df_total[col].iloc[-1], xy=(n_periods, df_total[col].iloc[-1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total[['PnL_Gamma', 'Total_Carry', 'PnL_Theta']].sum(1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_path = df_price_paths.loc[:, 8]\n",
    "gamma_array = np.array([bs_gamma(S=s, K=K, sigma=sigma_i, T=T*(1-t/n_periods), r=r) for t,s in zip(df_ptf.index, stock_path)])\n",
    "\n",
    "(0.5*gamma_array*(stock_path**2)*(np.log(stock_path/stock_path.shift(1))**2-(sigma_i**2)/len(stock_path))).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.log(stock_path/stock_path.shift(1)).var()*10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.5*df_call['Call_Gamma']*(stock_path**2)*(np.log(stock_path/stock_path.shift(1))**2-(sigma_i**2)/10000)).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sigma_i**2)/n_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(stock_path/stock_path.shift(1))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_path = df_price_paths.loc[:, 0]\n",
    "\n",
    "df_call = call_ptf(stock_path = stock_path, K=K, T=T,sigma=sigma_i, r=r)\n",
    "df_ptf = -delta_hedged_ptf(stock_path = stock_path, K=K,T=T, sigma=sigma_a, r=r)\n",
    "\n",
    "df_total = df_call.merge(df_ptf, right_index=True, left_index=True)\n",
    "\n",
    "df_total['PnL_Total'] = df_total[['Call_PnL','Ptf_Total']].sum(axis=1)\n",
    "df_total['PnL_Delta_Total'] = df_total.PnL_Delta + df_total.Ptf_Stock.diff(1).cumsum() + df_total.Cash_Rebalance.cumsum()\n",
    "df_total['Total_Carry'] = df_total['PnL_Carry'] + df_total['Daily_Interest'].cumsum()\n",
    "\n",
    "\n",
    "df_total[['PnL_Total','PnL_Gamma','PnL_Delta_Total','PnL_Theta','Total_Carry']].plot()\n",
    "\n",
    "for col in ['PnL_Total','PnL_Gamma','PnL_Delta_Total','PnL_Theta','Total_Carry']:\n",
    "    \n",
    "    plt.annotate('%.2f' % df_total[col].iloc[-1], xy=(n_periods, df_total[col].iloc[-1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Minimum Variance Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. begin with sorting your IV data – or each trading day, you will need BS option price as\n",
    "implied vol percentage, delta, and vega: ($ V_{t} $,$ \\delta_{bs} $,$ \\nu_{bs} $). <br> \n",
    "The term structure for option expiry $ 1M, 3M, 6M, 9M, 12M $, weekly expiries not necessary. <br> \n",
    "Key choice to make here, if\n",
    "you are going to study Delta for out of the money call strikes, in addition to about ATM\n",
    "buckets $ 0.45 < \\delta_{bs} <0.55 $ – each strike means a separate a,b,c history for each expiry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dtpyes = {'[QUOTE_UNIXTIME]': int,\n",
    "               ' [QUOTE_READTIME]' : object,\n",
    "               ' [QUOTE_DATE]': str,\n",
    "               ' [QUOTE_TIME_HOURS]': float, \n",
    "               ' [UNDERLYING_LAST]': float,\n",
    "               ' [EXPIRE_DATE]': object,\n",
    "               ' [EXPIRE_UNIX]': int,\n",
    "               ' [DTE]': float,\n",
    "               ' [C_DELTA]': object,\n",
    "               ' [C_GAMMA]': object, \n",
    "               ' [C_VEGA]': object,\n",
    "               ' [C_THETA]': object, \n",
    "               ' [C_RHO]': object, \n",
    "               ' [C_IV]': object, \n",
    "               ' [C_VOLUME]':object, \n",
    "               ' [C_LAST]': object,\n",
    "               ' [C_SIZE]': object,\n",
    "               ' [C_BID]': object, \n",
    "               ' [C_ASK]':object, \n",
    "               ' [STRIKE]': object, \n",
    "               ' [P_BID]':object,\n",
    "               ' [P_ASK]':object,  \n",
    "               ' [P_SIZE]':object, \n",
    "               ' [P_LAST]':object,\n",
    "               ' [P_DELTA]': object,\n",
    "               ' [P_GAMMA]': object,\n",
    "               ' [P_VEGA]': object, \n",
    "               ' [P_THETA]': object, \n",
    "               ' [P_RHO]':object,\n",
    "               ' [P_IV]':object,\n",
    "               ' [P_VOLUME]': object,\n",
    "               ' [STRIKE_DISTANCE]': float,\n",
    "               ' [STRIKE_DISTANCE_PCT]': float}\n",
    "\n",
    "csv_files = sorted(os.listdir('spx_eod_data'))\n",
    "\n",
    "df_option_data = pd.DataFrame()\n",
    "\n",
    "for file in csv_files:\n",
    "\n",
    "    df_option_data = pd.concat([df_option_data,\n",
    "                                pd.read_csv(filepath_or_buffer=f'spx_eod_data/{file}', \n",
    "                                            dtype=dict_dtpyes)\n",
    "                                ])\n",
    "\n",
    "# df_option_data = pd.read_csv(filepath_or_buffer='spx_eod_data/spx_eod_201001.txt')\n",
    "\n",
    "#Parse Data\n",
    "df_option_data.columns = [x.strip().replace('[','').replace(']','') for x in df_option_data.columns]\n",
    "df_option_data['QUOTE_DATE'] = [datetime.strptime(x.strip(),'%Y-%m-%d') for x in df_option_data.QUOTE_DATE]\n",
    "df_option_data['EXPIRE_DATE'] = [datetime.strptime(x.strip(),'%Y-%m-%d') for x in df_option_data.EXPIRE_DATE]\n",
    "\n",
    "#df_option_data = df_option_data[[not((df_option_data.loc[x]==' ').any()) for x in df_option_data.index]]\n",
    "df_option_data = df_option_data.replace(' ', np.nan)\n",
    "df_option_data = df_option_data[~df_option_data.isna().any(axis=1)]\n",
    "df_option_data = df_option_data.loc[df_option_data.DTE > 14]\n",
    "\n",
    "for col in ['C_DELTA', 'C_GAMMA', 'C_VEGA', 'C_THETA', 'C_RHO', 'C_IV', 'C_VOLUME', 'C_LAST', 'C_BID', 'C_ASK',\n",
    "            'STRIKE', 'P_BID', 'P_ASK', 'P_LAST', 'P_DELTA', 'P_GAMMA', 'P_VEGA', 'P_THETA', 'P_RHO', 'P_IV', 'P_VOLUME', \n",
    "            'STRIKE_DISTANCE', 'STRIKE_DISTANCE_PCT']:\n",
    "    \n",
    "    df_option_data[col] = [float(x) for x in df_option_data[col]]\n",
    "\n",
    "df_option_data['C_MID'] = (df_option_data['C_ASK']+df_option_data['C_BID'])/2\n",
    "df_option_data['P_MID'] = (df_option_data['P_ASK']+df_option_data['P_BID'])/2\n",
    "\n",
    "df_option_data = df_option_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_option_data['C_BS'] = [black_scholes(S=S,K=K,sigma=sigma,T=T/360,r=0) \n",
    "                          for S,K,sigma,T in zip(df_option_data['UNDERLYING_LAST'],\n",
    "                                                 df_option_data['STRIKE'],\n",
    "                                                 df_option_data['C_IV'], \n",
    "                                                 df_option_data['DTE'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. compute your dependent variable and run the fitting on $ \\delta_{bs} $,$ \\delta^2_{bs} $. <br>Dependent side based\n",
    "on daily option price changes $ \\Delta V_{t} $, and you will need $( \\Delta S_{t} , S_{t}) $ as well as Greeks noted\n",
    "above. <br> The exact data columns will depend on how you organise regression or do SLSQP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "cal = USFederalHolidayCalendar()\n",
    "\n",
    "holidays = cal.holidays(start=df_option_data.QUOTE_DATE.min(), \n",
    "                        end=df_option_data.QUOTE_DATE.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_option_data.loc[:,'C_VOLUME'],bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_option_data.loc[:,'C_VOLUME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls = df_option_data.set_index(['QUOTE_DATE','EXPIRE_UNIX','STRIKE'])[['UNDERLYING_LAST', 'DTE', 'C_DELTA', 'C_VEGA', 'C_IV', 'C_LAST','C_MID','C_BS','C_VOLUME']]\n",
    "df_calls['QUOTE_DATE'] = df_calls.index.get_level_values(0)\n",
    "\n",
    "df_calls = df_calls[(df_calls.C_DELTA < .95)&(df_calls.C_DELTA > .05)]\n",
    "df_calls = df_calls[~df_calls.index.get_level_values(0).isin(holidays)].copy()\n",
    "\n",
    "\n",
    "# Eliminate outliers prices compared to Black Scholes price\n",
    "\n",
    "q75, q25 = np.percentile((df_calls['C_LAST']-df_calls['C_BS']).values,\n",
    "                          [75,25])\n",
    "intr_qr = q75-q25\n",
    "\n",
    "cut_max = q75+(1.5*intr_qr)\n",
    "cut_min = q25-(1.5*intr_qr)\n",
    "\n",
    "df_calls = df_calls[(df_calls['C_LAST']-df_calls['C_BS'] > cut_min) \n",
    "                    & (df_calls['C_LAST']-df_calls['C_BS'] < cut_max)].copy()\n",
    "\n",
    "quote_dates = sorted(df_calls.index.get_level_values(0).unique())\n",
    "\n",
    "df_calls_diff = df_calls.loc[quote_dates[0]].merge(\n",
    "    df_calls.loc[quote_dates[1]], \n",
    "    left_index=True, \n",
    "    right_index=True, \n",
    "    suffixes=('_t1','_t0'), \n",
    "    how='inner')\n",
    "\n",
    "\n",
    "for i in range(len(quote_dates[2:])):\n",
    "    df_calls_diff = pd.concat([df_calls_diff,\n",
    "                               df_calls.loc[quote_dates[i+1]].merge(\n",
    "                                   df_calls.loc[quote_dates[i+2]], \n",
    "                                   left_index=True,\n",
    "                                   right_index=True,\n",
    "                                   suffixes=('_t1','_t0'),\n",
    "                                   how='inner')],\n",
    "                     axis=0)\n",
    "    \n",
    "df_calls_diff = df_calls_diff[df_calls_diff['C_LAST_t1']-df_calls_diff['C_LAST_t0'] != 0]\n",
    "    \n",
    "df_calls_diff['delta_price'] = df_calls_diff['C_LAST_t0'] - df_calls_diff['C_LAST_t1']\n",
    "#df_calls_diff['delta_price'] = df_calls_diff['C_BS_t0'] - df_calls_diff['C_BS_t1']\n",
    "df_calls_diff['delta_S'] = df_calls_diff['UNDERLYING_LAST_t0'] - df_calls_diff['UNDERLYING_LAST_t1']\n",
    "\n",
    "df_calls_diff['delta_price_perc'] = (df_calls_diff['C_LAST_t0'] - df_calls_diff['C_LAST_t1'])/df_calls_diff['C_LAST_t1']\n",
    "df_calls_diff['delta_S_perc'] = (df_calls_diff['UNDERLYING_LAST_t0'] - df_calls_diff['UNDERLYING_LAST_t1'])/df_calls_diff['UNDERLYING_LAST_t1']\n",
    "\n",
    "df_calls_diff['delta_IV'] = df_calls_diff['C_IV_t0']-df_calls_diff['C_IV_t1']\n",
    "\n",
    "df_calls_diff['BS_Delta_Bucket'] = [round(x*10)/10 for x in df_calls_diff.C_DELTA_t1]\n",
    "df_calls_diff['Expiry_Bucket'] = pd.cut(df_calls_diff.DTE_t1,[14, 30, 91, 182, 365, df_calls_diff.DTE_t1.max()],\n",
    "                                        labels=['1M', '3M', '6M', '9M', '12M'])\n",
    "\n",
    "df_calls_diff = df_calls_diff[abs(df_calls_diff.delta_S_perc) > 1e-4].copy()\n",
    "df_calls_diff = df_calls_diff.set_index(['QUOTE_DATE_t1','BS_Delta_Bucket','Expiry_Bucket'])\n",
    "\n",
    "df_calls_diff = df_calls_diff[df_calls_diff.C_VOLUME_t0!=0].copy()\n",
    "df_calls_diff['delta_IV'] = df_calls_diff['C_IV_t0'] - df_calls_diff['C_IV_t1']\n",
    "\n",
    "df_calls_diff['y'] = (df_calls_diff['delta_price']/df_calls_diff['delta_S']-df_calls_diff['C_DELTA_t1'])*df_calls_diff['UNDERLYING_LAST_t1']*np.sqrt(df_calls_diff['DTE_t1']/360)/(df_calls_diff['C_VEGA_t1']*100)\n",
    "df_calls_diff['y_perc'] = (df_calls_diff['delta_price_perc']/df_calls_diff['delta_S_perc']-df_calls_diff['C_DELTA_t1'])*np.sqrt(df_calls_diff['DTE_t1']/360)/(df_calls_diff['C_VEGA_t1']*100)\n",
    "\n",
    "df_calls_diff['delta_S_perc/sqrt_t'] = df_calls_diff['delta_S_perc']/np.sqrt(df_calls_diff['DTE_t0']/360)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Eliminate outliers on y\n",
    "q75, q25 = np.percentile(df_calls_diff.y, [75,25])\n",
    "intr_qr = q75-q25\n",
    "\n",
    "cut_max = q75+(1.5*intr_qr)\n",
    "cut_min = q25-(1.5*intr_qr)\n",
    "\n",
    "df_calls_diff = df_calls_diff[(df_calls_diff['y'] > cut_min) & (df_calls_diff['y'] < cut_max)].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_calls['C_BS']-df_calls['C_LAST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_calls_diff['y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_calls_diff['y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def quadratic_fit(df_option_prices):\n",
    "\n",
    "#     df = df_option_prices.groupby(['Expiry_Bucket','BS_Delta_Bucket'],\n",
    "#                                   observed=True).y.mean()\n",
    "\n",
    "#     expiry_buckets  = df.index.get_level_values(0).unique()\n",
    "\n",
    "#     df_result = pd.DataFrame(index=expiry_buckets,\n",
    "#                              columns=['a', 'b', 'c'])\n",
    "\n",
    "#     for expiry in expiry_buckets:\n",
    "\n",
    "#         c,b,a = np.polyfit(y=df.loc[expiry],\n",
    "#                            x=df.loc[expiry].index,\n",
    "#            deg=2)\n",
    "        \n",
    "#         df_result.loc[expiry,['a', 'b', 'c']] = [a, b, c]\n",
    "\n",
    "#     return df_result\n",
    "\n",
    "\n",
    "# for i in range(0, len(df_quote_dates)-21*36):\n",
    "\n",
    "#     training_period = df_quote_dates.loc[i:i+21*36].values\n",
    "#     testing_period = df_quote_dates.loc[i+21*36:i+21*36+30].values\n",
    "\n",
    "#     df_params.loc[training_period[-1], ['a', 'b', 'c']] = quadratic_fit(df_calls_diff.loc[training_period]).values\n",
    "\n",
    "#     print(training_period[-1])\n",
    "\n",
    "#df_params['minus_b'] = -df_params['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_PERIOD = 21*36 #36 months\n",
    "TESTING_PERIOD= 60 #1 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quote_dates = pd.Series(df_calls_diff.index.get_level_values(0).unique())\n",
    "\n",
    "# i = len(df_quote_dates)-TRAINING_PERIOD\n",
    "# testing_period = df_quote_dates.loc[i:i+TRAINING_PERIOD].values\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "lists = [\n",
    "   df_quote_dates.loc[TRAINING_PERIOD:].values,\n",
    "   df_calls_diff.index.get_level_values(2).unique().categories.to_list() + ['Total']\n",
    "   \n",
    "]\n",
    "\n",
    "df_params = pd.DataFrame(columns=['a','b','c'],\n",
    "                         index=pd.MultiIndex.from_tuples(itertools.product(*lists)))\n",
    "\n",
    "df_params.index.names = ['end_testing', 'expiry_bucket']\n",
    "\n",
    "df_params['start_testing'] = df_params.index.get_level_values(0).map(\n",
    "    {end:start for \n",
    "     end,start in \n",
    "     zip(df_quote_dates.loc[TRAINING_PERIOD:].values, df_quote_dates.loc[:].values)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "\n",
    "training_period = df_quote_dates.loc[i:i+21*36].values\n",
    "testing_period = df_quote_dates.loc[i+21*36:i+21*36+30].values\n",
    "\n",
    "\n",
    "print(quadratic_fit_perc(df_calls_diff.loc[training_period]).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quote_dates = pd.Series(df_calls_diff.index.get_level_values(0).unique())\n",
    "\n",
    "import itertools\n",
    "\n",
    "lists = [\n",
    "   df_quote_dates.loc[TRAINING_PERIOD:].values,\n",
    "   df_calls_diff.index.get_level_values(2).unique().categories.to_list() + ['Total']\n",
    "   \n",
    "]\n",
    "\n",
    "df_params = pd.DataFrame(columns=['a','b','c'],\n",
    "                         index=pd.MultiIndex.from_tuples(itertools.product(*lists)))\n",
    "\n",
    "df_params.index.names = ['end_testing', 'expiry_bucket']\n",
    "\n",
    "df_params['start_testing'] = df_params.index.get_level_values(0).map(\n",
    "    {end:start for \n",
    "     end,start in \n",
    "     zip(df_quote_dates.loc[TRAINING_PERIOD:].values, df_quote_dates.loc[:].values)})\n",
    "\n",
    "\n",
    "def get_r_squared(df_option_prices):\n",
    "\n",
    "    df = df_option_prices[['delta_IV', 'delta_S_perc', 'DTE_t1']].copy()\n",
    "    df['x'] = df['delta_S_perc']/np.sqrt(df['DTE_t1']/360)\n",
    "    result = pd.Series(index=sorted(df.index.get_level_values(1).unique()))\n",
    "\n",
    "    for bs_bucket in sorted(df.index.get_level_values(1).unique()):\n",
    "\n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(y=df.xs(bs_bucket, level='BS_Delta_Bucket').delta_IV,\n",
    "                                                                        x=df.xs(bs_bucket, level='BS_Delta_Bucket').x)\n",
    "        \n",
    "        result.loc[bs_bucket] = r_value**2\n",
    "        \n",
    "    return result\n",
    "    \n",
    "    \n",
    "def quadratic_fit(df_option_prices):\n",
    "\n",
    "    df = df_option_prices.groupby(['Expiry_Bucket','BS_Delta_Bucket'],\n",
    "                                  observed=True).y.mean()\n",
    "\n",
    "    expiry_buckets  = df.index.get_level_values(0).unique().to_list() + ['Total']\n",
    "\n",
    "    df_result = pd.DataFrame(index=expiry_buckets,\n",
    "                             columns=['a', 'b', 'c'])\n",
    "\n",
    "    for expiry in expiry_buckets[:-1]:\n",
    "\n",
    "        c,b,a = np.polyfit(y=df.loc[expiry],\n",
    "                           x=df.loc[expiry].index,\n",
    "           deg=2)\n",
    "        \n",
    "        df_result.loc[expiry,['a', 'b', 'c']] = [a, b, c]\n",
    "    \n",
    "    c,b,a = np.polyfit(y=df_option_prices.groupby(['BS_Delta_Bucket'],\n",
    "                                                  observed=True).y.mean(),\n",
    "                        x=df_option_prices.groupby(['BS_Delta_Bucket'],\n",
    "                                                  observed=True).y.mean().index,\n",
    "        deg=2)\n",
    "    \n",
    "    df_result.loc['Total',['a', 'b', 'c']] = [a, b, c]\n",
    "\n",
    "    return df_result\n",
    "\n",
    "for i in range(0, len(df_quote_dates)-TRAINING_PERIOD):\n",
    "\n",
    "    training_period = df_quote_dates.loc[i:i+TRAINING_PERIOD].values\n",
    "\n",
    "    df_params.loc[training_period[-1], ['a', 'b', 'c']] = quadratic_fit(df_calls_diff.loc[training_period]).values\n",
    "    #df_r_squared.loc[training_period[-1]] = get_r_squared(df_calls_diff.loc[training_period])\n",
    "\n",
    "df_params['minus_b'] = -df_params['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=6, ncols=1, figsize=(25,40))\n",
    "\n",
    "fig.suptitle('Rolling Estimation of parameters \\n 36 months period', \n",
    "             fontsize=30)\n",
    "\n",
    "\n",
    "sns.lineplot(df_params.xs('1M',level='expiry_bucket')[['a','minus_b','c']]\n",
    "             ,ax=ax[0])\n",
    "ax[0].set_title('1 Month Expiry')\n",
    "\n",
    "sns.lineplot(df_params.xs('3M',level='expiry_bucket')[['a','minus_b','c']]\n",
    "             ,ax=ax[1])\n",
    "ax[1].set_title('3 Months Expiry')\n",
    "\n",
    "sns.lineplot(df_params.xs('6M',level='expiry_bucket')[['a','minus_b','c']]\n",
    "             ,ax=ax[2])\n",
    "ax[2].set_title('6 Months Expiry')\n",
    "\n",
    "sns.lineplot(df_params.xs('9M',level='expiry_bucket')[['a','minus_b','c']]\n",
    "             ,ax=ax[3])\n",
    "ax[3].set_title('9 Months Expiry')\n",
    "\n",
    "sns.lineplot(df_params.xs('12M',level='expiry_bucket')[['a','minus_b','c']]\n",
    "             ,ax=ax[4])\n",
    "ax[4].set_title('12 Months Expiry')\n",
    "\n",
    "sns.lineplot(df_params.xs('Total',level='expiry_bucket')[['a','minus_b','c']]\n",
    "             ,ax=ax[5])\n",
    "ax[5].set_title('Total')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_calls_diff['C_BS_t0']-df_calls_diff['C_LAST_t0'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i=len(df_quote_dates)-21*36\n",
    "i=0\n",
    "training_period = df_quote_dates.loc[i:i+21*36].values\n",
    "\n",
    "plt.scatter(x=df_calls_diff.loc[training_period].xs('3M',level='Expiry_Bucket').xs(.5,level='BS_Delta_Bucket').C_DELTA_t1.to_numpy(),\n",
    "            y=df_calls_diff.loc[training_period].xs('3M',level='Expiry_Bucket').xs(.5,level='BS_Delta_Bucket').y.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_data = pd.read_csv('2013-01-16options.csv')\n",
    "\n",
    "df_comp_data = df_comp_data.loc[(df_comp_data.underlying == 'SPX') & (df_comp_data.volume > 0) & (df_comp_data.expiration > '2013-03-01')]\n",
    "df_comp_data = df_comp_data[df_comp_data.strike == 1450]\n",
    "df_comp_data = df_comp_data[df_comp_data.type == 'call']\n",
    "\n",
    "df_comp_data.sort_values('expiration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_option_data[(df_option_data['QUOTE_DATE'] == '2013-01-16')&(df_option_data['STRIKE'] == 1450)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expiry_bucket = 'Total'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "ax.plot(df_params.xs(expiry_bucket,level=1).index,\n",
    "         df_params.xs(expiry_bucket,level=1)[['a','b','c']]*[1,-1,1]\n",
    "         )\n",
    "\n",
    "\n",
    "ax2.plot(df_calls_diff.xs('6M', level='Expiry_Bucket').loc[df_params.index.get_level_values(0).min():].groupby('QUOTE_DATE_t1').C_IV_t0.mean().rolling(30).mean(),\n",
    "         label='IV',\n",
    "         color='r')\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assesing Gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sse_bs(df_option_prices, expiry_bucket, delta_bucket):\n",
    "\n",
    "#     df = (df_option_prices\n",
    "#           .xs(delta_bucket,level='BS_Delta_Bucket')\n",
    "#           .xs(expiry_bucket, level='Expiry_Bucket'))\n",
    "    \n",
    "#     epsilon_bs = df.delta_price - df.C_DELTA_t1*df.delta_S\n",
    "\n",
    "#     return sum(epsilon_bs**2)\n",
    "\n",
    "\n",
    "# def sse_mv(df_option_prices, df_params, expiry_bucket, delta_bucket):\n",
    "\n",
    "#     df = (df_option_prices\n",
    "#           .xs(delta_bucket,level='BS_Delta_Bucket')\n",
    "#           .xs(expiry_bucket, level='Expiry_Bucket'))\n",
    "    \n",
    "#     a,b,c = df_params.loc[expiry_bucket,['a','b','c']]\n",
    "    \n",
    "#     epsilon_bs = df.delta_price - df.C_DELTA_t1*df.delta_S\n",
    "#     epsilon_mv = epsilon_bs - (((df.C_VEGA_t1*100)*df.delta_S)/(np.sqrt(df.DTE_t1/360)*df.UNDERLYING_LAST_t1))*(a+b*df.C_DELTA_t1 + c*(df.C_DELTA_t1**2))\n",
    "\n",
    "\n",
    "#     return sum(epsilon_mv**2)\n",
    "\n",
    "\n",
    "# def gain_mv(df_option_prices, df_params, expiry_bucket, delta_bucket):\n",
    "\n",
    "#     _sse_bs = sse_bs(df_option_prices, expiry_bucket, delta_bucket)\n",
    "#     _sse_mv = sse_mv(df_option_prices, df_params, expiry_bucket, delta_bucket)\n",
    "\n",
    "#     return 1-_sse_mv/_sse_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING_PERIOD = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare df_gain_n_observations\n",
    "lists = [\n",
    "   df_quote_dates.loc[TRAINING_PERIOD+1:].iloc[:-TESTING_PERIOD],\n",
    "   sorted(df_calls_diff.index.get_level_values(1).unique())\n",
    "   ]\n",
    "\n",
    "df_gain_n_observations = pd.DataFrame(index=pd.MultiIndex.from_tuples(itertools.product(*lists)),\n",
    "                                      columns=df_calls_diff.index.get_level_values(2).unique().categories)\n",
    "\n",
    "df_gain_n_observations.index.names = ['start_testing','delta_bucket']\n",
    "\n",
    "#declare df_r_squared\n",
    "lists = [\n",
    "   df_quote_dates.loc[TRAINING_PERIOD+1:].iloc[:-TESTING_PERIOD],\n",
    "   sorted(df_calls_diff.index.get_level_values(1).unique()) + ['Total']\n",
    "   ]\n",
    "\n",
    "df_r_squared = pd.DataFrame(index=df_quote_dates.loc[TRAINING_PERIOD+1:].iloc[:-TESTING_PERIOD],\n",
    "                            columns=sorted(df_calls_diff.index.get_level_values(1).unique()))\n",
    "\n",
    "lists = [\n",
    "   df_quote_dates.loc[TRAINING_PERIOD+1:].iloc[:-TESTING_PERIOD],\n",
    "   sorted(df_calls_diff.index.get_level_values(1).unique()) + ['Total']\n",
    "   ]\n",
    "\n",
    "#df_gain_mv\n",
    "df_gain_mv = pd.DataFrame(index=pd.MultiIndex.from_tuples(itertools.product(*lists)),\n",
    "                          columns=df_calls_diff.index.get_level_values(2).unique().categories)\n",
    "\n",
    "df_gain_mv.index.names = ['start_testing','delta_bucket']\n",
    "df_gain_mv['Total'] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0, len(df_quote_dates)-TRAINING_PERIOD-TESTING_PERIOD-1):\n",
    "    \n",
    "        testing_period = df_quote_dates.loc[i+TRAINING_PERIOD: i+TRAINING_PERIOD+TESTING_PERIOD].values\n",
    "\n",
    "        df_loop = pd.merge(df_calls_diff.loc[testing_period[1:]].reset_index(),\n",
    "                           df_params.loc[testing_period[0],['a','b','c']].reset_index(),\n",
    "                           left_on = 'Expiry_Bucket',\n",
    "                           right_on = 'expiry_bucket'\n",
    "                           )\n",
    "\n",
    "        df_loop['epsilon_bs'] = df_loop['delta_price'] - df_loop['BS_Delta_Bucket']*df_loop['delta_S']\n",
    "\n",
    "        df_loop['Delta_MV'] = df_loop['BS_Delta_Bucket'] + (df_loop['C_VEGA_t1']*100\n",
    "                                                            *(df_loop['a']+df_loop['b']*df_loop['BS_Delta_Bucket']+df_loop['c']*(df_loop['BS_Delta_Bucket']**2))\n",
    "                                                            /(np.sqrt(df_loop['DTE_t1']/360)*df_loop['UNDERLYING_LAST_t1']))\n",
    "\n",
    "        df_loop['epsilon_mv'] = df_loop['delta_price'] - df_loop['Delta_MV']*df_loop['delta_S']\n",
    "\n",
    "        df_epsilon_bs = (df_loop.groupby(['BS_Delta_Bucket','Expiry_Bucket'],\n",
    "                                        observed=True)\n",
    "                                        .apply(lambda x: sum((x.epsilon_bs)**2))\n",
    "                                        .unstack())\n",
    "\n",
    "        df_epsilon_bs['Total'] = (df_loop\n",
    "                                        .groupby('BS_Delta_Bucket',\n",
    "                                                observed=True)\n",
    "                                                .apply(lambda x: sum((x.epsilon_bs)**2)))\n",
    "\n",
    "\n",
    "        df_epsilon_bs.loc['Total'] = (df_loop\n",
    "                                      .groupby('Expiry_Bucket',\n",
    "                                               observed=True)\n",
    "                                               .apply(lambda x: sum((x.epsilon_bs)**2)))\n",
    "\n",
    "        df_epsilon_bs.loc['Total', 'Total'] = sum(df_loop['epsilon_bs']**2)\n",
    "\n",
    "        df_epsilon_mv = (df_loop.groupby(['BS_Delta_Bucket','Expiry_Bucket'],\n",
    "                                        observed=True)\n",
    "                                        .apply(lambda x: sum((x.epsilon_mv)**2))\n",
    "                                        .unstack())\n",
    "\n",
    "        df_epsilon_mv['Total'] = (df_loop\n",
    "                                        .groupby('BS_Delta_Bucket',\n",
    "                                                observed=True)\n",
    "                                                .apply(lambda x: sum((x.epsilon_mv)**2)))\n",
    "\n",
    "\n",
    "        df_epsilon_mv.loc['Total'] = (df_loop\n",
    "                                        .groupby('Expiry_Bucket',\n",
    "                                                observed=True)\n",
    "                                                .apply(lambda x: sum((x.epsilon_mv)**2)))\n",
    "\n",
    "        df_epsilon_mv.loc['Total', 'Total'] = sum(df_loop['epsilon_mv']**2)\n",
    "\n",
    "        if len(df_epsilon_mv.columns) < len(df_gain_mv.loc[testing_period[1]].columns):\n",
    "\n",
    "                for col in set(df_gain_mv.loc[testing_period[1]].columns)-set(df_epsilon_mv.columns):\n",
    "\n",
    "                        df_epsilon_mv[col] = np.nan\n",
    "\n",
    "        if len(df_epsilon_bs.columns) < len(df_gain_mv.loc[testing_period[1]].columns):\n",
    "\n",
    "                for col in set(df_gain_mv.loc[testing_period[1]].columns)-set(df_epsilon_bs.columns):\n",
    "\n",
    "                        df_epsilon_bs[col] = np.nan\n",
    "\n",
    "        df_epsilon_bs = df_epsilon_bs[df_gain_mv.loc[testing_period[1]].columns]\n",
    "        df_epsilon_mv = df_epsilon_mv[df_gain_mv.loc[testing_period[1]].columns]\n",
    "\n",
    "        df_gain_mv.loc[testing_period[1]].loc[df_epsilon_mv.index] = (1 - df_epsilon_mv/df_epsilon_bs)\n",
    "\n",
    "        \n",
    "        df_loop_observations = (df_loop.groupby(['BS_Delta_Bucket','Expiry_Bucket'], observed=True)\n",
    "                                .QUOTE_DATE_t1.count()\n",
    "                                .unstack()[df_gain_n_observations.loc[testing_period[1]].columns]\n",
    "                                .values)\n",
    "        \n",
    "        df_gain_n_observations.loc[testing_period[1]] = df_loop_observations\n",
    "        df_r_squared.loc[testing_period[1]] = get_r_squared(df_loop.set_index(['QUOTE_DATE_t1','BS_Delta_Bucket', 'Expiry_Bucket']))\n",
    "        \n",
    "        # #remove data with less than 10 comparisons in the period\n",
    "        # df_n_observations = df_loop.groupby(['BS_Delta_Bucket','Expiry_Bucket'], observed=True).QUOTE_DATE_t1.count().unstack()\n",
    "        # df_n_observations['Total'] = df_n_observations.sum(axis=1)\n",
    "\n",
    "        # df_n_observations = df_n_observations[df_gain_mv.loc[testing_period[1]].columns]\n",
    "        # df_gain_mv.loc[testing_period[0]][df_n_observations < 10] = np.nan\n",
    "\n",
    "df_gain_mv = df_gain_mv.astype(float)\n",
    "df_r_squared = df_r_squared.astype(float)\n",
    "\n",
    "df_gain_n_observations['Total'] = df_gain_n_observations.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.groupby('delta_bucket').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_loop.groupby(['BS_Delta_Bucket','Expiry_Bucket'], observed=True)\n",
    "                        .QUOTE_DATE_t1.count().unstack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loop_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.groupby('delta_bucket').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r_squared.mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r_squared.loc[testing_period[1]] = get_r_squared(df_loop.set_index(['QUOTE_DATE_t1','BS_Delta_Bucket', 'Expiry_Bucket']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.groupby('delta_bucket').mean().Total.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_r_squared(df_loop.set_index(['QUOTE_DATE_t1','BS_Delta_Bucket', 'Expiry_Bucket']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_n_observations = df_gain_n_observations.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_n_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_n_observations['Total'] = df_gain_n_observations.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_n_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_n_observations['Total'].groupby(['start_testing','delta_bucket']).mean().unstack().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_n_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_n_observations.groupby('start_testing').mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_n_observations.groupby('start_testing').mean()['9M'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_n_observations.xs(.1,level='delta_bucket').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_n_observations.xs(.1,level='delta_bucket').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.groupby('delta_bucket').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.groupby('start_testing').mean().Total.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff.loc[training_period]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loop.set_index(['QUOTE_DATE_t1','BS_Delta_Bucket', 'Expiry_Bucket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_r_squared(df_loop.set_index(['QUOTE_DATE_t1','BS_Delta_Bucket', 'Expiry_Bucket']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epsilon_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_period[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.xs(.1,level='delta_bucket')['3M'].iloc[:-100].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epsilon_bs[df_gain_mv.loc[testing_period[1]].columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_gain_mv = df_gain_mv.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quote_dates.loc[i+TRAINING_PERIOD: i+TRAINING_PERIOD+20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3215 - TRAINING_PERIOD-1\n",
    "testing_period = df_quote_dates.loc[i+TRAINING_PERIOD: i+TRAINING_PERIOD+60].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_period[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-df_epsilon_mv/df_epsilon_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epsilon_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epsilon_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params[df_params.start_testing == '2013-11-04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n_observations = df_loop.groupby(['BS_Delta_Bucket','Expiry_Bucket'], observed=True).QUOTE_DATE_t1.count().unstack()\n",
    "df_n_observations['Total'] = df_n_observations.sum(axis=1)\n",
    "\n",
    "df_n_observations = df_n_observations[df_gain_mv.loc[testing_period[1]].columns]\n",
    "\n",
    "df_gain_mv.loc[testing_period[1]][df_n_observations < 10] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing_period = df_quote_dates[(df_quote_dates>'2013-11-03')&(df_quote_dates<='2013-12-13')].values\n",
    "\n",
    "# df_loop = pd.merge(df_calls_diff.loc[testing_period[1:]].reset_index(),\n",
    "#                     df_params.loc[testing_period[0],['a','b','c']].reset_index(),\n",
    "#                     left_on = 'Expiry_Bucket',\n",
    "#                     right_on = 'expiry_bucket'\n",
    "#                     )\n",
    "\n",
    "# df_loop['epsilon_bs'] = df_loop['delta_price'] - df_loop['BS_Delta_Bucket']*df_loop['delta_S']\n",
    "\n",
    "# df_loop['Delta_MV'] = df_loop['BS_Delta_Bucket'] + (df_loop['C_VEGA_t1']*100\n",
    "#                                                     *(df_loop['a']+df_loop['b']*df_loop['BS_Delta_Bucket']+df_loop['c']*(df_loop['BS_Delta_Bucket']**2))\n",
    "#                                                     /(np.sqrt(df_loop['DTE_t1']/360)*df_loop['UNDERLYING_LAST_t1']))\n",
    "\n",
    "# df_loop['epsilon_mv'] = df_loop['delta_price'] - df_loop['Delta_MV']*df_loop['delta_S']\n",
    "\n",
    "# df_epsilon_bs = (df_loop.groupby(['BS_Delta_Bucket','Expiry_Bucket'],\n",
    "#                                 observed=True)\n",
    "#                                 .apply(lambda x: sum((x.epsilon_bs)**2))\n",
    "#                                 .unstack())\n",
    "\n",
    "# df_epsilon_bs['Total'] = (df_loop\n",
    "#                                 .groupby('BS_Delta_Bucket',\n",
    "#                                         observed=True)\n",
    "#                                         .apply(lambda x: sum((x.epsilon_bs)**2)))\n",
    "\n",
    "\n",
    "# df_epsilon_bs.loc['Total'] = (df_loop\n",
    "#                                 .groupby('Expiry_Bucket',\n",
    "#                                         observed=True)\n",
    "#                                         .apply(lambda x: sum((x.epsilon_bs)**2)))\n",
    "\n",
    "# df_epsilon_bs.loc['Total', 'Total'] = sum(df_loop['epsilon_bs']**2)\n",
    "\n",
    "# df_epsilon_mv = (df_loop.groupby(['BS_Delta_Bucket','Expiry_Bucket'],\n",
    "#                                 observed=True)\n",
    "#                                 .apply(lambda x: sum((x.epsilon_mv)**2))\n",
    "#                                 .unstack())\n",
    "\n",
    "# df_epsilon_mv['Total'] = (df_loop\n",
    "#                                 .groupby('BS_Delta_Bucket',\n",
    "#                                         observed=True)\n",
    "#                                         .apply(lambda x: sum((x.epsilon_mv)**2)))\n",
    "\n",
    "\n",
    "# df_epsilon_mv.loc['Total'] = (df_loop\n",
    "#                                 .groupby('Expiry_Bucket',\n",
    "#                                         observed=True)\n",
    "#                                         .apply(lambda x: sum((x.epsilon_mv)**2)))\n",
    "\n",
    "# df_epsilon_mv.loc['Total', 'Total'] = sum(df_loop['epsilon_mv']**2)\n",
    "\n",
    "# if len(df_epsilon_mv.columns) < len(df_gain_mv.loc[testing_period[1]].columns):\n",
    "\n",
    "#         for col in set(df_gain_mv.loc[testing_period[1]].columns)-set(df_epsilon_mv.columns):\n",
    "\n",
    "#                 df_epsilon_mv[col] = np.nan\n",
    "\n",
    "# if len(df_epsilon_bs.columns) < len(df_gain_mv.loc[testing_period[1]].columns):\n",
    "\n",
    "#         for col in set(df_gain_mv.loc[testing_period[1]].columns)-set(df_epsilon_bs.columns):\n",
    "\n",
    "#                 df_epsilon_bs[col] = np.nan\n",
    "\n",
    "# df_epsilon_bs = df_epsilon_bs[df_gain_mv.loc[testing_period[1]].columns]\n",
    "# df_epsilon_mv = df_epsilon_mv[df_gain_mv.loc[testing_period[1]].columns]\n",
    "\n",
    "# #df_gain_mv.loc[testing_period[1]].loc[df_epsilon_mv.index] = (1 - df_epsilon_mv/df_epsilon_bs)\n",
    "\n",
    "# print(testing_period[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitted_line(x, params):\n",
    "\n",
    "  a = params[0]\n",
    "  b = params[1]\n",
    "  c = params[2]\n",
    "\n",
    "  return a + b * x + c * x**2\n",
    "\n",
    "df_delta_plot = df_loop.groupby('BS_Delta_Bucket')['Delta_MV'].mean()\n",
    "df_delta_plot = df_delta_plot.to_frame()\n",
    "\n",
    "fitted_data = [fitted_line(x, df_params.loc[testing_period[0],['a','b','c']].loc['Total'].values) \n",
    "               for x in df_delta_plot.index]\n",
    "\n",
    "fitted_data = fitted_data*df_loop.groupby('BS_Delta_Bucket').apply(lambda x: np.mean(x.C_VEGA_t1*100/(x.UNDERLYING_LAST_t0*np.sqrt(x.DTE_t1/360))))\n",
    "\n",
    "plt.scatter(y=df_delta_plot.Delta_MV - df_delta_plot.index,\n",
    "            x=df_delta_plot.index)\n",
    "\n",
    "plt.plot(df_delta_plot.index, fitted_data, c='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quote_dates[df_quote_dates == '2023-04-05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv['3M'].xs(.1, level='delta_bucket').idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_gain_mv['Total'].xs('Total', level='delta_bucket'), bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.groupby('delta_bucket').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_gain_mv.groupby('delta_bucket').mean().iloc[1:7],annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_calls_diff.groupby(['BS_Delta_Bucket', 'Expiry_Bucket'])['C_VOLUME_t0'].sum().unstack(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff.groupby(['BS_Delta_Bucket', 'Expiry_Bucket'])['C_VOLUME_t0'].count().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y=df_calls_diff.loc[testing_period].xs(.5, level='BS_Delta_Bucket').delta_IV,\n",
    "            x=df_calls_diff.loc[testing_period].xs(.5, level='BS_Delta_Bucket').apply(lambda x: x.delta_S_perc/np.sqrt(x.DTE_t1/360) ,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_bucket = .2\n",
    "\n",
    "plt.scatter(y=df_calls_diff.loc[testing_period].xs(bs_bucket, level='BS_Delta_Bucket').delta_IV,\n",
    "            x=df_calls_diff.loc[testing_period].xs(bs_bucket, level='BS_Delta_Bucket')['delta_S_perc/sqrt_t'])\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(y=df_calls_diff.loc[testing_period].xs(bs_bucket, level='BS_Delta_Bucket').delta_IV,\n",
    "                                                                     x=df_calls_diff.loc[testing_period].xs(bs_bucket, level='BS_Delta_Bucket')['delta_S_perc/sqrt_t'])\n",
    "\n",
    "print(slope)\n",
    "print(r_value**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff['delta_S_perc/sqrt_t'] = df_calls_diff['delta_S_perc']/np.sqrt(df_calls_diff['DTE_t0']/360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_calls_diff.groupby(['BS_Delta_Bucket','Expiry_Bucket']).count().UNDERLYING_LAST_t1.unstack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(slope, intercept, r_value, p_value, std_err )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_calls_diff.delta_IV)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff.loc[df_calls_diff.delta_IV.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff.loc[(df_calls_diff['C_BS_t0']-df_calls_diff['C_LAST_t0']).idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(df_calls_diff['C_BS_t0']-df_calls_diff['C_LAST_t0'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff.loc['2019-05-17'].loc[.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff.groupby(['BS_Delta_Bucket', 'Expiry_Bucket'])['C_VOLUME_t1'].count().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff.groupby(['BS_Delta_Bucket', 'Expiry_Bucket'])['C_VOLUME_t1'].mean().unstack().sum(1).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff.groupby(['BS_Delta_Bucket', 'Expiry_Bucket'])['C_VOLUME_t1'].mean().unstack().sum(0).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv['Total'].xs('Total', level='delta_bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_calls_diff.loc[testing_period[1:]]\n",
    "                        .groupby('Expiry_Bucket',\n",
    "                                observed=True)\n",
    "                                .apply(lambda x: sum((x.delta_price-x.C_DELTA_t1*x.delta_S)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_period[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_period[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epsilon_bs = (df_calls_diff.loc[testing_period[1:]]\n",
    "                .groupby(['BS_Delta_Bucket','Expiry_Bucket'],\n",
    "                        observed=True)\n",
    "                        .apply(lambda x: sum((x.delta_price-x.C_DELTA_t1*x.delta_S)**2))\n",
    "                        .unstack())\n",
    "\n",
    "df_epsilon_bs['Total'] = (df_calls_diff.loc[testing_period[1:]]\n",
    "                            .groupby('BS_Delta_Bucket',\n",
    "                                    observed=True)\n",
    "                                    .apply(lambda x: sum((x.delta_price-x.C_DELTA_t1*x.delta_S)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epsilon_bs.loc['Total'] = (df_calls_diff.loc[testing_period[1:]]\n",
    "                        .groupby('Expiry_Bucket',\n",
    "                                observed=True)\n",
    "                                .apply(lambda x: sum((x.delta_price-x.C_DELTA_t1*x.delta_S)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff.loc[testing_period[1:]].apply(lambda x: (x.delta_price-x.C_DELTA_t1*x.delta_S)**2,axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.merge(df_calls_diff.loc[testing_period[1:]].reset_index(),\n",
    "                                  df_params.loc[testing_period[0],['a','b','c']].reset_index(),\n",
    "                                  left_on = 'Expiry_Bucket',\n",
    "                                  right_on = 'expiry_bucket'\n",
    "                                  )\n",
    "                                  .groupby(['Expiry_Bucket'],\n",
    "                                           observed=True)\n",
    "                        .apply(lambda x: sum((x.delta_price-x.C_DELTA_t1*x.delta_S\n",
    "                                                -(x.C_VEGA_t1*100)*x.delta_S_perc*(x.a + x.b*x.C_DELTA_t1 + x.c*(x.C_DELTA_t1**2))/np.sqrt(x.DTE_t1/360)\n",
    "                                                )**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_calls_diff.loc[testing_period[1:]].reset_index(),\n",
    "                                  df_params.loc[testing_period[0],['a','b','c']].reset_index(),\n",
    "                                  left_on = 'Expiry_Bucket',\n",
    "                                  right_on = 'expiry_bucket'\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((pd.merge(df_calls_diff.loc[testing_period[1:]].reset_index(),\n",
    "                                  df_params.loc[testing_period[0],['a','b','c']].reset_index(),\n",
    "                                  left_on = 'Expiry_Bucket',\n",
    "                                  right_on = 'expiry_bucket'\n",
    "                                  )\n",
    "                                  .groupby(['BS_Delta_Bucket'],\n",
    "                                           observed=True)\n",
    "                        .apply(lambda x: (x.delta_price-x.C_DELTA_t1*x.delta_S\n",
    "                                                -(x.C_VEGA_t1*100)*x.delta_S_perc*(x.a + x.b*x.C_DELTA_t1 + x.c*(x.C_DELTA_t1**2))/np.sqrt(x.DTE_t1/360)))),bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((pd.merge(df_calls_diff.loc[testing_period[1:]].reset_index(),\n",
    "                                  df_params.loc[testing_period[0],['a','b','c']].reset_index(),\n",
    "                                  left_on = 'Expiry_Bucket',\n",
    "                                  right_on = 'expiry_bucket'\n",
    "                                  )\n",
    "                                  .groupby(['BS_Delta_Bucket'],\n",
    "                                           observed=True)\n",
    "                        .apply(lambda x: (x.delta_price-x.C_DELTA_t1*x.delta_S\n",
    "                                                ))),bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff.loc[testing_period[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epsilon_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epsilon_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.loc[:'2022-01-01'].groupby('delta_bucket')['1M'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv['Total'].xs(.6,level='delta_bucket').loc[:'2022-01-01'].head(100).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params.xs('6M', level='expiry_bucket')[['a','minus_b','c']].head(90).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epsilon_mv['Total'] = df_epsilon_mv.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epsilon_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_quote_dates)-21*36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.fillna(0).groupby('delta_bucket')[df_gain_mv.columns].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_calls_diff.loc[testing_period[1:]]\n",
    " .groupby(['BS_Delta_Bucket','Expiry_Bucket'],\n",
    "          observed=True)\n",
    " .apply(lambda x: sum((x.delta_price-x.C_DELTA_t1*x.delta_S)**2)).unstack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params.loc[testing_period[0],['a','b','c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse_bs(df_calls_diff.loc[testing_period[1:]],'6M',.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse_mv(df_calls_diff.loc[testing_period[1:]],\n",
    "       df_params.loc[testing_period[0]],'6M',.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_mv(df_calls_diff.loc[testing_period[1:]],\n",
    "       df_params.loc[testing_period[0]],'6M',.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_period[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = [\n",
    "   df_quote_dates.loc[21*36:].values,\n",
    "   df_calls_diff.index.get_level_values(2).unique().categories\n",
    "   \n",
    "]\n",
    "\n",
    "df_params = pd.DataFrame(columns=['a','b','c'],\n",
    "                         index=pd.MultiIndex.from_tuples(itertools.product(*lists)))\n",
    "\n",
    "df_params.index.names = ['end_testing', 'expiry_bucket']\n",
    "\n",
    "df_params['start_testing'] = df_params.index.get_level_values(0).map(\n",
    "    {end:start for \n",
    "     end,start in \n",
    "     zip(df_quote_dates.loc[21*36:].values, df_quote_dates.loc[:].values)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff.index.get_level_values(1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "testing_period = df_quote_dates.loc[i+21*36:i+21*36+30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_mv(df_calls_diff.loc[testing_period[1:]],\n",
    "       df_params.loc[testing_period[0]],\n",
    "       '6M',\n",
    "       .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.loc[testing_period[1]].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_quote_dates)-(21*36+30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1000\n",
    "training_period = df_quote_dates.loc[i:i+21*36].values\n",
    "testing_period = df_quote_dates.loc[i+21*36:i+21*36+30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_mv(df_calls_diff.loc[testing_period[1:]],\n",
    "                                                            df_params.loc[testing_period[0]],\n",
    "                                                            '6M',\n",
    "                                                            .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.xs(.9,level='delta_bucket')['3M'].loc[:'2022-01-01'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.xs(.2,level='delta_bucket')['6M'].loc[:'2022-01-01'].to_frame().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.loc['2013-10-29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.loc[:'2022-01-01'].groupby('delta_bucket').mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epsilon_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epsilon_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epsilon_mv.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-df_epsilon_mv.sum(1)/df_epsilon_bs.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quote_dates.loc[933]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_period = (df_quote_dates[(df_quote_dates > '2013-10-29')\n",
    "               &(df_quote_dates < '2013-12-13')]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_period[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff.loc[testing_period[1:]].xs('6M', level='Expiry_Bucket').xs(.2, level='BS_Delta_Bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_period = (df_quote_dates[(df_quote_dates > '2013-10-29')\n",
    "               &(df_quote_dates < '2013-12-13')]).to_numpy()\n",
    "\n",
    "df_epsilon_bs = (df_calls_diff.loc[testing_period[1:]]\n",
    "                .groupby(['BS_Delta_Bucket','Expiry_Bucket'],\n",
    "                        observed=True)\n",
    "                        .apply(lambda x: sum((x.delta_price-x.C_DELTA_t1*x.delta_S)**2))\n",
    "                        .unstack())\n",
    "\n",
    "df_epsilon_mv = (pd.merge(df_calls_diff.loc[testing_period[1:]].reset_index(),\n",
    "                            df_params.loc[testing_period[0],['a','b','c']].reset_index(),\n",
    "                            left_on = 'Expiry_Bucket',\n",
    "                            right_on = 'expiry_bucket'\n",
    "                            )\n",
    "                            .groupby(['BS_Delta_Bucket','Expiry_Bucket'],\n",
    "                                    observed=True)\n",
    "                .apply(lambda x: sum((x.delta_price-x.C_DELTA_t1*x.delta_S\n",
    "                                        -x.C_VEGA_t1*100*x.delta_S_perc*(x.a + x.b*x.C_DELTA_t1 + x.c*(x.C_DELTA_t1**2))/np.sqrt(x.DTE_t1/360)\n",
    "                                        )**2))\n",
    "                .unstack())\n",
    "\n",
    "df_epsilon_mv = df_epsilon_mv.loc[df_gain_mv.loc[testing_period[1]].index\n",
    "                                ,df_gain_mv.loc[testing_period[1]].columns]\n",
    "\n",
    "df_epsilon_bs = df_epsilon_bs.loc[df_gain_mv.loc[testing_period[1]].index\n",
    "                                ,df_gain_mv.loc[testing_period[1]].columns]\n",
    "\n",
    "\n",
    "df_gain_mv.loc[testing_period[1]] = (1 - df_epsilon_mv/df_epsilon_bs).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.loc[testing_period[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_calls_diff.loc[testing_period[1:]]\n",
    "                .groupby(['BS_Delta_Bucket', 'Expiry_Bucket'],\n",
    "                        observed=True)\n",
    "                        .apply(lambda x: sum((x.delta_price-x.C_DELTA_t1*x.delta_S)**2))\n",
    "                        .unstack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epsilon_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_epsilon_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 - df_epsilon_mv/df_epsilon_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_mv(df_calls_diff.loc[testing_period[3:]],\n",
    "                                                            df_params.loc[testing_period[4]],\n",
    "                                                            '6M',\n",
    "                                                            .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_mv(df_calls_diff.loc[testing_period[1:]],\n",
    "                                                            df_params.loc[testing_period[0]],\n",
    "                                                            expiry,\n",
    "                                                            delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for delta in df_gain_mv.loc[testing_period[1]].index:\n",
    "\n",
    "    for expiry in df_gain_mv.loc[testing_period[1]].columns:\n",
    "\n",
    "\n",
    "        try:\n",
    "            df_gain_mv.loc[testing_period[1], delta][expiry] = gain_mv(df_calls_diff.loc[testing_period[1:]],\n",
    "                                                            df_params.loc[testing_period[0]],\n",
    "                                                            expiry,\n",
    "                                                            delta)\n",
    "        except:\n",
    "            \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3000*2/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.loc[testing_period[1], delta][expiry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gain_mv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-45.86514506071337/86.80437565410338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse_helio(params, df_option_prices, expiry_bucket):\n",
    "\n",
    "    a = params[0]\n",
    "    b = params[1]\n",
    "    c = params[2]\n",
    "\n",
    "    df = df_option_prices.xs(expiry_bucket,level='Expiry_Bucket')\n",
    "    df = df.groupby(['BS_Delta_Bucket'])[['delta_S', 'delta_price', 'UNDERLYING_LAST_t1', 'C_VEGA_t1', 'DTE_t1']].mean()\n",
    "\n",
    "    print(len(df))\n",
    "\n",
    "    epsilon_bs = df['delta_price'] - df.index*df['delta_S']\n",
    "    epsilon_mv = epsilon_bs - (df['C_VEGA_t1']*100*df['delta_S']/(df['UNDERLYING_LAST_t1']*np.sqrt(df.DTE_t1/360)))*(a+b*df.index+c*(df.index**2))\n",
    "\n",
    "    return sum(epsilon_mv**2)\n",
    "\n",
    "\n",
    "for i in range(0, len(df_quote_dates)-21*36):\n",
    "\n",
    "    testing_period = df_quote_dates.loc[i:i+21*36].values\n",
    "    training_period = df_quote_dates.loc[i+21*36:i+21*36+30].values\n",
    "\n",
    "    for expiry in df_params.loc[testing_period[-1]].index:\n",
    "\n",
    "        result = minimize(fun=sse_helio,\n",
    "            x0=np.array([0, 0, 0]),\n",
    "            args=(df_calls_diff.loc[testing_period], expiry),\n",
    "            method='SLSQP',\n",
    "            )\n",
    "\n",
    "        df_params.loc[testing_period[-1]].loc[expiry,['a','b','c']] = result.x\n",
    "\n",
    "    print(testing_period[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_diff.loc['2018-4-01':'2019-6-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_params.xs('3M',level=1)[['a','b','c']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_params.loc[testing_period[-1]].loc['3M'] = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse_mv(params, df_option_prices, expiry_bucket):\n",
    "\n",
    "    a = params[0]\n",
    "    b = params[1]\n",
    "    c = params[2]\n",
    "\n",
    "    df = df_option_prices.xs(expiry_bucket,level='Expiry_Bucket')\n",
    "\n",
    "    epsilon_bs = df['delta_price_perc'] - df['C_DELTA_t1']*df['delta_S_perc']\n",
    "    epsilon_mv = epsilon_bs - (df['C_VEGA_t1']*100*df['delta_S_perc']/(np.sqrt(df.DTE_t1/360)))*(a+b*df['C_DELTA_t1']+c*(df['C_DELTA_t1']**2))\n",
    "\n",
    "    return sum(epsilon_mv**2)\n",
    "\n",
    "\n",
    "result = minimize(fun=sse_mv,\n",
    "         x0=np.array([0, 0, 0]),\n",
    "         args=(df_calls_diff.loc[testing_period], '3M'),\n",
    "         method='SLSQP',\n",
    "         )\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = result.x\n",
    "\n",
    "x = df_calls_diff.loc[df_calls_diff.QUOTE_DATE_t0 == df_calls_diff.QUOTE_DATE_t0.max()].xs('6M',level='Expiry_Bucket').C_DELTA_t0\n",
    "y = df_calls_diff.loc[df_calls_diff.QUOTE_DATE_t0 == df_calls_diff.QUOTE_DATE_t0.max()].xs('6M',level='Expiry_Bucket').apply(lambda row: row.C_VEGA_t0*100/(row.UNDERLYING_LAST_t0*np.sqrt(row.DTE_t0/360))*(a+b*row.C_DELTA_t0+c*(row.C_DELTA_t0**2)) ,axis=1)\n",
    "plt.scatter(x=x,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [a+b*x+c*(x**2) for x in df_calls_diff.C_DELTA_t1]*df_calls_diff.delta_S_perc/(np.sqrt(df_calls_diff.DTE_t1/360))\n",
    "y = df_calls_diff['C_IV_t0'] - df_calls_diff['C_IV_t1']\n",
    "\n",
    "\n",
    "slope, intercept, r, p, std_err = scipy.stats.linregress(x, y)\n",
    "\n",
    "def fitted_line(x):\n",
    "  return slope * x + intercept\n",
    "\n",
    "fitted_data = list(map(fitted_line, x))\n",
    "\n",
    "plt.scatter(x = x,\n",
    "            y = y)\n",
    "\n",
    "plt.plot(x, fitted_data,c='black')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"\"\"Linear Regression - Change in Implied vs Normalized Return: \\n\n",
    "      Slope:{slope}\\n\n",
    "      Intercept:{intercept}\\n  \n",
    "      R²: {r**2}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot((df_helio['C_IV_t0']-df_helio['C_IV_t1']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse data for CALLS\n",
    "\n",
    "df_calls_data = df_option_data.drop(['P_BID', 'P_ASK', 'P_SIZE', 'P_LAST', 'P_DELTA', \n",
    "                                     'P_GAMMA', 'P_VEGA', 'P_THETA', 'P_RHO', 'P_IV','P_VOLUME'], axis=1)\n",
    "\n",
    "df_calls_data = df_calls_data[(df_calls_data.C_DELTA < .95)&(df_calls_data.C_DELTA > .05)]\n",
    "df_calls_data['BS_Delta_Bucket'] = [round(x*10)/10 for x in df_calls_data.C_DELTA]\n",
    "\n",
    "df_calls_data['Expiry_Bucket'] = pd.cut(df_calls_data.DTE,[14,30,91, 182,365,2000],\n",
    "                                        labels=['1M', '3M', '6M', '9M', '12M'])\n",
    "\n",
    "#df_calls_data = df_calls_data.set_index(['BS_Delta_Bucket','Expiry_Bucket'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_data.set_index(['EXPIRE_UNIX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foo = df_calls_data.set_index(['BS_Delta_Bucket','Expiry_Bucket']).loc[(.5,'6M')]\n",
    "\n",
    "df_foo = df_foo.groupby('QUOTE_DATE')[['UNDERLYING_LAST', 'C_IV', 'C_LAST', 'C_DELTA', 'C_VEGA', 'DTE','C_MID','C_BS']].mean()\n",
    "\n",
    "df_foo['Delta_S'] = df_foo['UNDERLYING_LAST'].diff()/df_foo['UNDERLYING_LAST']\n",
    "df_foo['Delta_IV'] = df_foo['C_IV'].diff()\n",
    "\n",
    "df_foo = df_foo.dropna()\n",
    "\n",
    "x = df_foo['Delta_IV']\n",
    "y = df_foo['Delta_S']\n",
    "\n",
    "slope, intercept, r, p, std_err = scipy.stats.linregress(x, y)\n",
    "\n",
    "def fitted_line(x):\n",
    "  return slope * x + intercept\n",
    "\n",
    "fitted_data = list(map(fitted_line, x))\n",
    "\n",
    "plt.scatter(x = x,\n",
    "            y = y)\n",
    "\n",
    "plt.plot(x, fitted_data)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"\"\"Linear Regression - Change in Asset Price vs Change in Implied Vol: \\n\n",
    "      Slope:{slope}\\n\n",
    "      Intercept:{intercept}\\n  \n",
    "      R²: {r**2}\"\"\")\n",
    "\n",
    "x = (df_foo['UNDERLYING_LAST'].diff()*df_foo['C_DELTA']).dropna()\n",
    "y = df_foo['C_BS'].diff().dropna()\n",
    "\n",
    "\n",
    "slope, intercept, r, p, std_err = scipy.stats.linregress(x, y)\n",
    "\n",
    "def fitted_line(x):\n",
    "  return slope * x + intercept\n",
    "\n",
    "fitted_data = list(map(fitted_line, x))\n",
    "\n",
    "plt.scatter(x = x,\n",
    "            y = y)\n",
    "\n",
    "plt.plot(x, fitted_data)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"\"\"Linear Regression - Change in Option Price vs PnL Delta: \\n\n",
    "      Slope:{slope}\\n\n",
    "      Intercept:{intercept}\\n  \n",
    "      R²: {r**2}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime('2010-01-08')-pd.to_datetime('2010-04-15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_data.iloc[1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_scholes(S=df_calls_data.iloc[1000].UNDERLYING_LAST,\n",
    "              K=df_calls_data.iloc[1000].STRIKE,\n",
    "              sigma=df_calls_data.iloc[1000].C_IV,\n",
    "              T=df_calls_data.iloc[1000].DTE/360,\n",
    "              r=-0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_delta(S=df_calls_data.iloc[1000].UNDERLYING_LAST,\n",
    "         K=df_calls_data.iloc[1000].STRIKE,\n",
    "         sigma=df_calls_data.iloc[1000].C_IV,\n",
    "         T=df_calls_data.iloc[1000].DTE/360,\n",
    "         r=-0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_vega(S=df_calls_data.iloc[1000].UNDERLYING_LAST,\n",
    "              K=df_calls_data.iloc[1000].STRIKE,\n",
    "              sigma=df_calls_data.iloc[1000].C_IV,\n",
    "              T=df_calls_data.iloc[1000].DTE/360,\n",
    "              r=-0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_data = df_calls_data.groupby(['Expiry_Bucket','QUOTE_DATE','BS_Delta_Bucket'])[['UNDERLYING_LAST', 'C_IV', 'C_MID', 'C_DELTA', 'C_VEGA', 'DTE']].mean().copy()\n",
    "df_calls_data = df_calls_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_data.index.get_level_values(0).unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse(params):\n",
    "\n",
    "    total_sse = 0.0\n",
    "\n",
    "    a = params[0]\n",
    "    b = params[1]\n",
    "    c = params[2]\n",
    "\n",
    "    for expiry in df_calls_data.index.get_level_values(0).unique().to_list():\n",
    "\n",
    "        delta_f = df_calls_data.xs(expiry).groupby(level=1)['C_MID'].diff()\n",
    "        delta_s = df_calls_data.xs(expiry).groupby(level=1)['UNDERLYING_LAST'].diff()\n",
    "        delta_bs = df_calls_data.xs(expiry).groupby(level=1).diff().index.get_level_values(1)\n",
    "        vega_bs = df_calls_data.xs(expiry)['C_VEGA']*100\n",
    "        dte = df_calls_data.xs(expiry)['DTE']/360\n",
    "        underlying = df_calls_data.xs(expiry)['UNDERLYING_LAST']\n",
    "        \n",
    "        error_bs = delta_f - delta_bs*delta_s\n",
    "        error_mv = error_bs - (vega_bs*delta_s/(np.sqrt(dte)*underlying))*(a + b*delta_bs + c*(delta_bs**2))\n",
    "        error_mv = error_mv.dropna()\n",
    "    \n",
    "        total_sse += sum(error_mv**2)\n",
    "    \n",
    "    return total_sse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse(np.array([0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foo2 = df_calls_data.xs('6M', level=1)\n",
    "\n",
    "df_foo2 = df_foo2.groupby(['BS_Delta_Bucket','QUOTE_DATE'])[['UNDERLYING_LAST', 'C_IV', 'C_LAST', 'C_DELTA', 'C_VEGA', 'DTE']].mean()\n",
    "\n",
    "list_slopes = []\n",
    "\n",
    "for delta_bucket in df_foo2.index.get_level_values(0).unique():\n",
    "\n",
    "    df_loop = df_foo2.loc[delta_bucket]\n",
    "    df_loop['Delta_S'] = df_loop['UNDERLYING_LAST'].diff()/df_loop['UNDERLYING_LAST']\n",
    "    \n",
    "    df_loop['Delta_IV'] = df_loop['C_IV'].diff()\n",
    "\n",
    "    df_loop = df_loop.dropna()\n",
    "\n",
    "    x = df_loop['Delta_IV']\n",
    "    y = df_loop['Delta_S']\n",
    "\n",
    "    slope, intercept, r, p, std_err = scipy.stats.linregress(x, y)\n",
    "    fitted_data = list(map(fitted_line, x))\n",
    "\n",
    "    # plt.scatter(x = df_loop['Delta_IV'],\n",
    "    #             y = df_loop['Delta_S'])\n",
    "\n",
    "    # plt.plot(x, fitted_data)\n",
    "\n",
    "    # plt.show()\n",
    "    list_slopes.append(slope)\n",
    "    # print(f\"\"\"Linear Regression - Log Std Deviation of Prices vs Log Simulations: \\n\n",
    "    #     Slope:{slope}\\n\n",
    "    #     Intercept:{intercept}\\n  \n",
    "    #     R²: {r**2}\"\"\")\n",
    "    \n",
    "    # print(delta_bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foo2 = df_foo2.reset_index().sort_values(['QUOTE_DATE','BS_Delta_Bucket']).set_index(['QUOTE_DATE','BS_Delta_Bucket'])\n",
    "quote_dates = df_foo2.index.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_mv(df_t0, df_t1, a, b, c):\n",
    "\n",
    "    available_deltas = list(set(df_t0.index).intersection(df_t1.index))\n",
    "    df_t0 = df_t0.loc[available_deltas]\n",
    "    df_t1 = df_t1.loc[available_deltas]\n",
    "\n",
    "    epsilon_bs = (df_t0.C_LAST-df_t1.C_LAST) - df_t1.C_DELTA*(df_t0.UNDERLYING_LAST - df_t1.UNDERLYING_LAST)\n",
    "    epsilon_mv = epsilon_bs - ((df_t1.C_VEGA*100*(df_t0.UNDERLYING_LAST - df_t1.UNDERLYING_LAST))/(np.sqrt(df_t1.DTE/360)*df_t1.UNDERLYING_LAST))*(a+b*df_t1.index+c*(df_t1.index**2))\n",
    "    return epsilon_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_mv_total = []\n",
    "\n",
    "for i in range(len(quote_dates)-1):\n",
    "\n",
    "    epsilon_mv_total.append(epsilon_mv(df_foo2.loc[quote_dates[i]], df_foo2.loc[quote_dates[i-1]], a=0,b=0,c=0).to_list())\n",
    "\n",
    "SSE = sum([sum(np.array(error)**2) for error in epsilon_mv_total])\n",
    "print(np.sqrt(SSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_dates[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sum([sum(epsilon_mv(df_foo2.loc[quote_dates[i]], df_foo2.loc[quote_dates[i-1]], a=0,b=0,c=0)**2) for i in range(len(quote_dates)-1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def sse_mv(params):\n",
    "\n",
    "    a = params[0]\n",
    "    b = params[1]\n",
    "    c= params[2]\n",
    "\n",
    "    epsilon_mv_total = []\n",
    "\n",
    "    for i in range(len(quote_dates)-1):\n",
    "\n",
    "        epsilon_mv_total.append(epsilon_mv(df_foo2.loc[quote_dates[i]], df_foo2.loc[quote_dates[i-1]], a=a,b=b,c=c).to_list())\n",
    "\n",
    "    return sum([sum(np.array(error)**2) for error in epsilon_mv_total])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(fun=sse,\n",
    "         x0=np.array([0, 0, 0]),\n",
    "         method='Nelder-Mead',\n",
    "         )\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sse_mv(result.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = result.x\n",
    "\n",
    "y = df_calls_data.xs('2012-12-31',level=1).xs('9M', level=0)\n",
    "plt.scatter(x=y.index,y=y.index + y.C_VEGA*10/(y.UNDERLYING_LAST*np.sqrt(y.DTE/360))*(a+b*y.index+c*(y.index**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y.C_VEGA/(y.UNDERLYING_LAST*np.sqrt(y.DTE/360))*(a+b*y.index+c*(y.index**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c*(y.index**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_option_data.iloc[28364]\n",
    "print(y.head(20))\n",
    "print(black_scholes(S=y.UNDERLYING_LAST,K=y.STRIKE,sigma=y.C_IV,T=y.DTE/360,r=0.0))\n",
    "bs_delta(S=y.UNDERLYING_LAST,K=y.STRIKE,sigma=y.C_IV,T=y.DTE/360,r=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sse_mv(np.array([-0.2,.4,-.5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sse(np.array([-3.090e+00, 1.269e+01, -1.925e+01])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for prettier numpy prints\n",
    "np.set_printoptions(precision = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse(np.array([0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sse(result.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(sse([0,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calls_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i/np.sqrt(360) for i in [-3.400e+00 ,1.478e+01, -2.341e+01]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foo2.loc[quote_dates[i-1]].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(df_foo2.loc[quote_dates[i-1]].index).intersection(df_foo2.loc[quote_dates[i]].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(epsilon_mv(df_foo2.loc[quote_dates[i]], df_foo2.loc[quote_dates[i-1]], a=-.0,b=0,c=0)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_mv(df_foo2.loc[quote_dates[i]], df_foo2.loc[quote_dates[i-1]], a=-.05,b=0,c=-.6).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_dates[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c=0,0,0\n",
    "i=30\n",
    "df_t0 = df_foo2.loc[quote_dates[i]]\n",
    "df_t1 = df_foo2.loc[quote_dates[i-1]]\n",
    "\n",
    "available_deltas = list(set(df_t0.index).intersection(df_t1.index))\n",
    "df_t0 = df_t0.loc[available_deltas]\n",
    "df_t1 = df_t1.loc[available_deltas]\n",
    "\n",
    "epsilon_bs = (df_t0.C_LAST-df_t1.C_LAST) - df_t1.C_DELTA*(df_t0.UNDERLYING_LAST - df_t1.UNDERLYING_LAST)\n",
    "epsilon_mv = epsilon_bs - ((df_t1.C_VEGA*(df_t0.UNDERLYING_LAST - df_t1.UNDERLYING_LAST))/(np.sqrt(df_t1.DTE/360)*df_t1.UNDERLYING_LAST))*(a+b*df_t1.index+c*(df_t1.index**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_t0.C_LAST-df_t1.C_LAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t1.C_DELTA*(df_t0.UNDERLYING_LAST - df_t1.UNDERLYING_LAST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(epsilon_bs**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=.0\n",
    "((df_t1.C_VEGA*100*(df_t0.UNDERLYING_LAST - df_t1.UNDERLYING_LAST))/(np.sqrt(df_t1.DTE/360)*df_t1.UNDERLYING_LAST))*(a+b*df_t1.index+c*(df_t1.index**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t0.UNDERLYING_LAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foo2.loc[quote_dates[i-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foo2.loc[quote_dates[i],['C_LAST', 'C_BID', 'C_ASK']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot((df_foo2.loc['2010-01-05'].C_LAST-df_foo2.loc['2010-01-06'].C_LAST)-(df_foo2.loc['2010-01-05'].UNDERLYING_LAST-df_foo2.loc['2010-01-06'].UNDERLYING_LAST)*df_foo2.loc['2010-01-05'].C_DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foo2.index.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_slopes = np.sqrt(df_foo2.groupby('BS_Delta_Bucket')['DTE'].mean().values/360)*list_slopes\n",
    "\n",
    "x = df_foo2.index.get_level_values(0).unique()\n",
    "y = list_slopes\n",
    "\n",
    "model = np.poly1d(np.polyfit(x, y, 2))\n",
    "\n",
    "#add fitted polynomial line to scatterplot\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, model(x))\n",
    "\n",
    "print(model)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_foo2.index.get_level_values(0).unique():\n",
    "\n",
    "    df_foo2.loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foo2.loc[.5].C_LAST.diff().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_foo2.loc[i].C_DELTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=.5\n",
    "plt.plot(df_foo2.loc[i].UNDERLYING_LAST.diff()*df_foo2.loc[i].C_DELTA)\n",
    "plt.plot(df_foo2.loc[i].C_LAST.diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foo2.loc[i].C_LAST.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $ \\Delta f - \\delta_{bs}\\Delta S = \\frac{\\nu_{bs}}{\\sqrt{T}}\\frac{\\Delta S}{S}(a+b\\delta_{bs}+\\delta^{2}_{bs}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_foo2.loc[i,'UNDERLYING_LAST'].diff()*df_foo2.loc[i,'C_VEGA']/(np.sqrt(df_foo2.loc[i,'DTE'])*df_foo2.loc[i,'UNDERLYING_LAST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (df_foo2.loc[i]['UNDERLYING_LAST'].diff()*df_foo2.loc[i]['C_DELTA']).dropna()\n",
    "y = df_foo2.loc[i]['C_LAST'].diff().dropna()\n",
    "\n",
    "\n",
    "slope, intercept, r, p, std_err = scipy.stats.linregress(x, y)\n",
    "\n",
    "def fitted_line(x):\n",
    "  return slope * x + intercept\n",
    "\n",
    "fitted_data = list(map(fitted_line, x))\n",
    "\n",
    "plt.scatter(x = x,\n",
    "            y = y)\n",
    "\n",
    "plt.plot(x, fitted_data)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"\"\"Linear Regression - Change in Option Price vs PnL Delta: \\n\n",
    "      Slope:{slope}\\n\n",
    "      Intercept:{intercept}\\n  \n",
    "      R²: {r**2}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "data = (x-y).values\n",
    "bins = 30\n",
    "\n",
    "bins = np.histogram(data, \n",
    "                    bins=30)[1]\n",
    "\n",
    "bins = [float(x) for x in bins]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25,16))\n",
    "\n",
    "sns.histplot(data,stat='density',\n",
    "                bins=30,\n",
    "                ax=ax)\n",
    "\n",
    "sns.lineplot(ax=ax,\n",
    "             x=bins,\n",
    "             y=gaussian(data=data,\n",
    "                        bins=bins),\n",
    "            color='red')\n",
    "\n",
    "\n",
    "textstr = '\\n'.join((\n",
    "    r'$\\mu=%.2f$' % (np.mean(data), ),\n",
    "    r'$\\mathrm{median}=%.2f$' % (np.median(data), ),\n",
    "    r'$\\sigma=%.2f$' % (np.std(data), ),\n",
    "    r'$\\frac{\\sigma}{\\mu}=%.2f$'% (np.std(data)*100/np.mean(data), )+'%'))\n",
    "\n",
    "ax.text(0.1, 0.95, textstr, \n",
    "            horizontalalignment='center', \n",
    "            verticalalignment='top', \n",
    "            transform=ax.transAxes, \n",
    "            bbox=props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "\n",
    "data = (x).values\n",
    "bins = 30\n",
    "\n",
    "bins = np.histogram(data, \n",
    "                    bins=30)[1]\n",
    "\n",
    "bins = [float(x) for x in bins]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25,16))\n",
    "\n",
    "sns.histplot(data,stat='density',\n",
    "                bins=30,\n",
    "                ax=ax)\n",
    "\n",
    "sns.lineplot(ax=ax,\n",
    "             x=bins,\n",
    "             y=gaussian(data=data,\n",
    "                        bins=bins),\n",
    "            color='red')\n",
    "\n",
    "\n",
    "textstr = '\\n'.join((\n",
    "    r'$\\mu=%.2f$' % (np.mean(data), ),\n",
    "    r'$\\mathrm{median}=%.2f$' % (np.median(data), ),\n",
    "    r'$\\sigma=%.2f$' % (np.std(data), ),\n",
    "    r'$\\frac{\\sigma}{\\mu}=%.2f$'% (np.std(data)*100/np.mean(data), )+'%'))\n",
    "\n",
    "ax.text(0.1, 0.95, textstr, \n",
    "            horizontalalignment='center', \n",
    "            verticalalignment='top', \n",
    "            transform=ax.transAxes, \n",
    "            bbox=props)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
